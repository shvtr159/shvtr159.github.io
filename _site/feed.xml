<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.2.0">Jekyll</generator><link href="https://shvtr159.github.io/feed.xml" rel="self" type="application/atom+xml" /><link href="https://shvtr159.github.io/" rel="alternate" type="text/html" /><updated>2022-02-15T20:34:52+09:00</updated><id>https://shvtr159.github.io/feed.xml</id><title type="html">Study Blog</title><subtitle>for study</subtitle><author><name>KYG</name></author><entry><title type="html">[논문 리뷰] Self-Supervised Pillar Motion Learning for Autonomous Driving</title><link href="https://shvtr159.github.io/%EB%85%BC%EB%AC%B8/self-supervised-pillar-motion-learning-for-autonomous-driving/" rel="alternate" type="text/html" title="[논문 리뷰] Self-Supervised Pillar Motion Learning for Autonomous Driving" /><published>2022-01-12T00:00:00+09:00</published><updated>2022-01-12T00:00:00+09:00</updated><id>https://shvtr159.github.io/%EB%85%BC%EB%AC%B8/self-supervised-pillar-motion-learning-for-autonomous-driving</id><content type="html" xml:base="https://shvtr159.github.io/%EB%85%BC%EB%AC%B8/self-supervised-pillar-motion-learning-for-autonomous-driving/">&lt;p&gt;본 논문은 CVPR 2021에 게재된 논문으로  CVPR 2019에 게재된 PointPillars라는 논문의 아이디어를 기반으로 Self-Supervised learning을 수행하였다. BEV로 표현하는 방법의 장점을 이용하기 위해 raw point cloud를 pillar로 organize한다. 이후 각각의 pillar 속도인 pillar motion을 예측한다. 이때, LiDAR의 sparse scan 특성 상 data가 조밀하지 않아 camera image로부터 얻어진 optical flow를 함께 사용한다.  이 구조는 다음과 같은 상호작용을 하며 학습한다.&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Point cloud는 optical flow에서 ego-motion을 제외하는데 도움을 준다.&lt;/li&gt;
  &lt;li&gt;Image motion은 pillar motion을 학습하는데 auxiliary(보조) regularization를 제공한다.&lt;/li&gt;
  &lt;li&gt;back-project된 optical flow에 의해 생성된 probabilistic motion masking은 point cloud에서 구조적 일관성을 유지하도록 한다.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;자세한 내용은 이 논문에서 설정한 Loss들을 확인해보면 알수 있다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/79836443/149094364-1b9ab86b-f4f0-4043-aa93-62bdae0e09bf.png&quot; alt=&quot;image&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;
&lt;center&gt;&lt;span style=&quot;color:rgb(150, 150, 150)&quot;&gt;pillar motion estimation을 위해 제안된 self-supervised learning framework의 schematic overview&lt;/span&gt;&lt;/center&gt;
&lt;h2 id=&quot;method&quot;&gt;Method&lt;/h2&gt;
&lt;h3 id=&quot;problem-formulation&quot;&gt;Problem Formulation&lt;/h3&gt;
&lt;p&gt;시간 $t$에서의 point cloud와 paired camera images를 $\mathcal{P}_ t = {\lbrace P_ i^t \rbrace}^{N_t}_ {i=1}$, $\mathcal{I}_ t = {\lbrace P_ i^t \rbrace}^{N_c}_ {i=1}$로 나타낸다($P_ i^t$ : point, $N_t$ : received point의 수, $I_ i^t$ : image, $N_c$ : 차에 장착된 camera의 수).&lt;/p&gt;

&lt;p&gt;다시 $\mathcal{P}_ t$는 겹치지 않는 pillar ${\lbrace \rho_ i^t \rbrace}^{N_p}_ {i=1}$로 이산화(discretized)된다($\rho_ i^t$ : pillar index, $N_p$ : pillar의 수). Pillar motion field는 $\mathcal{M}_ t = {\lbrace M_ i^t \rbrace}^{N_p}_ {i=1}$로 나타내면 다음 time에서의 각 pillar 위치는 다음과 같이 표현할 수 있다 : $\rho_ i^{
\sim t+1}=M_ i^t(\rho_i^t),\;M_ i^t\in\mathbb{R}^2$.&lt;/p&gt;

&lt;h3 id=&quot;lidar--based-structural-consistency&quot;&gt;LiDAR  based Structural Consistency&lt;/h3&gt;
&lt;p&gt;위에서 정의한 pillar motion $\mathcal{M}_ t$에 따라 각 pillar $\rho_i^t$의 motion vector $M_i^t$를 pillar 내 모든 point에 할당하여 point 별 motion을 얻을 수 있고, 수직 방향의 motion은 0으로 설정한다. 이렇게 point 별 motion을 얻으면 origin point cloud $\mathcal{P}_ t$로부터 다음 timestamp의 예상 point cloud인 $\widetilde{\mathcal{P}}_ {t+1}$를 얻을 수 있다.&lt;/p&gt;

&lt;p&gt;이 transformed point cloud $\widetilde{\mathcal{P}}_ {t+1}$와 실제 point cloud $\mathcal{P}_ {t+1}$간의 structural consistency를 pillar motion learning을 위한 free supervision으로 사용한다. 이를 나타내는 Loss는 다음과 같이 표현된다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/79836443/149133556-f71835ac-7fe7-4757-8f62-dad0b7bc3ed5.png&quot; alt=&quot;image&quot; class=&quot;align-center&quot; width=&quot;70%&quot; height=&quot;70%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;간단히 이야기하면, tramsform된 point들과 실제 point들 간에 한 point에서 가장 가까운 point와의 거리를 Loss로 사용한다고 할 수 있다. 그러나 LiDAR로 얻는 point cloud의 특성 상 $t$에서 얻은 point가 정확히 이동하여 $t+1$에 똑같이 존재할 수 없다. 때문에 이것만 사용하면 noise의 영향이 매우 크다.&lt;/p&gt;

&lt;h3 id=&quot;cross-sensor-motion-regularization&quot;&gt;Cross-Sensor Motion Regularization&lt;/h3&gt;
&lt;p&gt;LiDAR의 data가 sparse한것에 비해 카메라 image는 point cloud보다 dense하고 구분하기 쉬운 외관을 얻을 수 있다. 이 장점을 활용하기 위해 image도 같이 사용한다. 그 방법은 pillar motion을 projection하여 얻은 scene flow와 image로부터 얻은 optical flow를 비교하는 것이다.&lt;/p&gt;

&lt;p&gt;그러나 optical flow는 ego-motion, 즉 자기 자신이 움직이는것 때문에 관측하려는 물체의 실제 motion이 달라지게 된다. 때문에$I^t$와 $I^{t+1}$로 계산되는 $F^t$의 $(u,v)$픽셀에서의 optical flow는 다음과 같이 나타난다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/79836443/149141628-e5ce6a96-162d-4d41-bdfc-d4e66b7d103f.png&quot; alt=&quot;image&quot; class=&quot;align-center&quot; width=&quot;60%&quot; height=&quot;60%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;여기서, $I^t$와 관련된 point cloud $\mathcal{P}_ t$의 point $P^t_i$를 projection 했을 때 camera image에서의 위치는 다음과 같이 나타낼 수 있다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/79836443/149275347-bb378ace-973a-4922-91ea-3264c15c9e40.png&quot; alt=&quot;image&quot; class=&quot;align-center&quot; width=&quot;45%&quot; height=&quot;45%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;$K$는 camera intrinsic parameter이고, $T_{L\to C}$는 LiDAR와 camera간의 상대적 pose이다. 이를 이용하면 ego-motion에 의해 유도된 optical flow를 다음과 같이 계산할 수 있다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/79836443/149141290-141ad651-3805-4ca8-98b1-59b7103c91a7.png&quot; alt=&quot;image&quot; class=&quot;align-center&quot; width=&quot;75%&quot; height=&quot;75%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;이때 $T_{t \to t+1}$은 ego-vehicle의 pose 변화로, ego-vehicle의 움직이 포함된 optical flow에서 이를 고려하지 않은 optical flow를 빼줌으로써 순수하게 ego-vehicle의 motion만 계산하는 것이다. (2)번 식과 (4)번식을 합치면 순수한 $F_{obj}^t$만을 얻을 수 있다. 유의해야할 것은 정확한 $F_{ego}^t$를 계산하기 위해 projected point와 대응되는 pixel에서만 $F_{obj}^t$를 계산한다.&lt;/p&gt;

&lt;p&gt;이제 pillar 별 motion vector $M^t_i$를 3번 식을 이용해 대응되는 image로 projection하면 projected optical flow인 $\widetilde{\mathcal{P}}^t(u_i,v_i)$를 얻을 수 있다. 이렇게 얻어진 2가지 optical flow의 차이를 다음과 같은 식으로 표현하고, Loss로 사용한다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/79836443/149146801-fc942fd6-fbbb-4e5b-8487-d47da4288e82.png&quot; alt=&quot;image&quot; class=&quot;align-center&quot; width=&quot;70%&quot; height=&quot;70%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;이 loss는 이전의 structural consistency를 보조하고, sparse한 point cloud의 ambiguity를 완화한다. optical flow estimation과 관련하여, 전체 framework를 통합하여 self-supervised learning을 수행할 수 있도록 unsupervised 방법&lt;sup&gt;&lt;a href=&quot;#footnote_1&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;을 사용해 model을 training 할 수 있다.&lt;/p&gt;

&lt;h3 id=&quot;probabilistic-motion-masking&quot;&gt;Probabilistic Motion Masking&lt;/h3&gt;
&lt;p&gt;ego-motion을 제외하고 남은 object motion에서 멈춰있는 물체가 noise로 인해 움직이는것으로 인식되어 똑같이 weight를 가지게 되면 제대로 된 motion을 예측하기 어렵다. 때문에 여기서는 다음 식과 같은 확률적 motion masking을 이용해 해당 object가 static할 확률을 계산하여 weight를 조절할 수 있도록 하였다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/79836443/149274288-d8078642-1a3d-4b3e-9a3c-1e197ca4ec90.png&quot; alt=&quot;image&quot; class=&quot;align-center&quot; width=&quot;65%&quot; height=&quot;65%&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;optimization&quot;&gt;Optimization&lt;/h3&gt;
&lt;p&gt;optical flow 추정을 위한 spatical smoothness constraint와 유사하게 pillar motion learning에서도 유사한 local smoothness loss를 사용한다. spatical smoothness constraint란 인접한 pixel은 일반적으로 기준 pixel과 유사한 움직임을 가질것이라는 것에서 비롯된 제한이다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/79836443/149275784-111c8736-9b13-442f-9d72-c909cf1fdb38.png&quot; alt=&quot;image&quot; class=&quot;align-center&quot; width=&quot;75%&quot; height=&quot;75%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;$\mathcal{M}^x_t$와 $\mathcal{M}^y_t$는 예측한 pillar motion field $\mathcal{M}_ t$의 $x, y$ 성분이고, $\bigtriangledown_x, \bigtriangledown_y$는 $x, y$방향의 기울기이다. 이 Loss는 동일한 물체에 속한 pillar가 유사한 움직임을 가지도록 하는데 도움을 준다.&lt;/p&gt;

&lt;h3 id=&quot;total-loss&quot;&gt;Total Loss&lt;/h3&gt;
&lt;p&gt;total loss는 위에서 나온 3개의 loss term의 weighted sum으로 계산한다. $\lambda$는 balancing coefficient이다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/79836443/149296453-b4ff3f48-0adc-4d7a-b451-c8e4c2f5f41d.png&quot; alt=&quot;image&quot; class=&quot;align-center&quot; width=&quot;75%&quot; height=&quot;75%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;hr /&gt;
&lt;p&gt;&lt;a name=&quot;footnote_1&quot;&gt;1&lt;/a&gt;: Yang Wang, Yi Yang, Zhenheng Yang, Liang Zhao, Peng Wang, and Wei Xu. Occlusion aware unsupervised learning of optical flow. In CVPR, 2018.&lt;/p&gt;</content><author><name>KYG</name></author><category term="논문" /><summary type="html">본 논문은 CVPR 2021에 게재된 논문으로 CVPR 2019에 게재된 PointPillars라는 논문의 아이디어를 기반으로 Self-Supervised learning을 수행하였다. BEV로 표현하는 방법의 장점을 이용하기 위해 raw point cloud를 pillar로 organize한다. 이후 각각의 pillar 속도인 pillar motion을 예측한다. 이때, LiDAR의 sparse scan 특성 상 data가 조밀하지 않아 camera image로부터 얻어진 optical flow를 함께 사용한다. 이 구조는 다음과 같은 상호작용을 하며 학습한다. Point cloud는 optical flow에서 ego-motion을 제외하는데 도움을 준다. Image motion은 pillar motion을 학습하는데 auxiliary(보조) regularization를 제공한다. back-project된 optical flow에 의해 생성된 probabilistic motion masking은 point cloud에서 구조적 일관성을 유지하도록 한다.</summary></entry><entry><title type="html">[논문 리뷰] Deep Learning for 3D Point Clouds: A Survey</title><link href="https://shvtr159.github.io/%EB%85%BC%EB%AC%B8/deep-learning-for-3d-point-clouds-a-survey/" rel="alternate" type="text/html" title="[논문 리뷰] Deep Learning for 3D Point Clouds: A Survey" /><published>2021-12-30T00:00:00+09:00</published><updated>2021-12-30T00:00:00+09:00</updated><id>https://shvtr159.github.io/%EB%85%BC%EB%AC%B8/deep-learning-for-3d-point-clouds-a-survey</id><content type="html" xml:base="https://shvtr159.github.io/%EB%85%BC%EB%AC%B8/deep-learning-for-3d-point-clouds-a-survey/">&lt;p&gt;본 survey는 IEEE TPAMI에 게재된 것으로 2020년 까지 Point cloud를 사용하는 Deep Learning에 대해 정리하였다.&lt;sup&gt;&lt;a href=&quot;#footnote_1&quot;&gt;1&lt;/a&gt;&lt;/sup&gt; 다음과 같이 크게 3개의 task에 대해 설명하지만 이 글에서는 Segmentation을 제외한 2가지 task에 대해 정리한다.&lt;/p&gt;
&lt;h2 id=&quot;background&quot;&gt;Background&lt;/h2&gt;
&lt;h3 id=&quot;evaluation-metrics&quot;&gt;Evaluation Metrics&lt;/h3&gt;
&lt;p&gt;각 task를 평가하기 위해 다양한 방법이 사용된다. 주로 사용되는 방법은 다음과 같다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;3D shape classification&lt;/strong&gt; : Overall Accuracy(OA), mean class accuracy(mAcc). OA는 모든 etst instances에 대한 평균 accuracy이고, mAcc는 모든 shape classes의 평균 accuracy를 의미한다.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;3D object detection&lt;/strong&gt; : Average Precision(AP). precision-recall curve의 아래 면적으로 계산.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;3D single object tracker&lt;/strong&gt; : Precision, Success&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;3D multi object tracker&lt;/strong&gt; : Average Multi-Object Tracking Accuracy(AMOTA), Average Multi-Object Tracking Precision(AMOTP)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;3D point cloud segmentation&lt;/strong&gt; : OA, mean Intersection over Union(mIoU), mean class Accuracy(mAcc), mean Average Precision(mAP).&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;3d-shape-classification&quot;&gt;3D Shape Classification&lt;/h2&gt;
&lt;h3 id=&quot;1-multi-view-based-methods&quot;&gt;1. Multi-view based Methods&lt;/h3&gt;
&lt;p&gt;이 방법은 먼저 3D shape를 다양한 view로 projection을 하고 각 view에서의 feature를 추출한다. 그리고 이 feature들을 fu&lt;/p&gt;
&lt;h2 id=&quot;3d-object-detection-and-tracking&quot;&gt;3D Object Detection and Tracking&lt;/h2&gt;
&lt;h3 id=&quot;3d-object-detection&quot;&gt;3D Object Detection&lt;/h3&gt;
&lt;h3 id=&quot;3d-object-tracking&quot;&gt;3D Object Tracking&lt;/h3&gt;
&lt;p&gt;첫 frame에서 object의 위치가 주어지면, 연속되는 frame에서 이 object의 state를 추정하고 위치를 찾는다. Point cloud는 풍부한 geometric 정보를 사용할 수 있기 때문에 image 기반의 tracking에서 겪던 occlusion이나 조명 및 scale 변화같은 단점을 극복할 수 있다. image 기반 tracking에서 Siamese network를 성공적으로 사용한것이 기반해서 SC3D는 shape completion regularization을 사용하는 3D Siamese network를 제안하였다. 여기서는 먼저 Kalman filter를 사용해서 후보를 생성하고, shape regularization을 사용하여 model과 후보들을 encoding 하였다. 그리고 다음 frame에서 tracking 하는 object의 위치를 찾기 위해 cosine similarity를 사용한다.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;a name=&quot;footnote_1&quot;&gt;1&lt;/a&gt;: &lt;a href=&quot;https://ieeexplore.ieee.org/abstract/document/9127813&quot;&gt;Y. Guo, H. Wang, Q. Hu, H. Liu, L. Liu and M. Bennamoun, “Deep Learning for 3D Point Clouds: A Survey,” in IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 43, no. 12, pp. 4338-4364, 1 Dec. 2021, doi: 10.1109/TPAMI.2020.3005434.&lt;/a&gt;&lt;br /&gt;&lt;/p&gt;</content><author><name>KYG</name></author><category term="논문" /><summary type="html">본 survey는 IEEE TPAMI에 게재된 것으로 2020년 까지 Point cloud를 사용하는 Deep Learning에 대해 정리하였다.1 다음과 같이 크게 3개의 task에 대해 설명하지만 이 글에서는 Segmentation을 제외한 2가지 task에 대해 정리한다. Background Evaluation Metrics 각 task를 평가하기 위해 다양한 방법이 사용된다. 주로 사용되는 방법은 다음과 같다. 3D shape classification : Overall Accuracy(OA), mean class accuracy(mAcc). OA는 모든 etst instances에 대한 평균 accuracy이고, mAcc는 모든 shape classes의 평균 accuracy를 의미한다. 3D object detection : Average Precision(AP). precision-recall curve의 아래 면적으로 계산. 3D single object tracker : Precision, Success 3D multi object tracker : Average Multi-Object Tracking Accuracy(AMOTA), Average Multi-Object Tracking Precision(AMOTP) 3D point cloud segmentation : OA, mean Intersection over Union(mIoU), mean class Accuracy(mAcc), mean Average Precision(mAP).</summary></entry><entry><title type="html">[MLPR #] Unsupervised Classification 2 (미완)</title><link href="https://shvtr159.github.io/mlpr/mlpr-unsupervised-classification-2/" rel="alternate" type="text/html" title="[MLPR #] Unsupervised Classification 2 (미완)" /><published>2021-12-05T00:00:00+09:00</published><updated>2021-12-05T00:00:00+09:00</updated><id>https://shvtr159.github.io/mlpr/mlpr-unsupervised-classification-2</id><content type="html" xml:base="https://shvtr159.github.io/mlpr/mlpr-unsupervised-classification-2/">&lt;ul&gt;
  &lt;li&gt;Similarity and Similarity Measures&lt;/li&gt;
  &lt;li&gt;Chain Method of Clustering&lt;/li&gt;
  &lt;li&gt;Clustering Criterion Functions&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Iterative Optimization&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Clustering procedure – basic min. squared error&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;K-means Clustering&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Hierarchical Clustering&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;Mixture Densities: Gaussian Mixtures&lt;/li&gt;
  &lt;li&gt;Component Analysis: PCA, ICA&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;iterative-optimization&quot;&gt;Iterative Optimization&lt;/h2&gt;</content><author><name>KYG</name></author><category term="MLPR" /><summary type="html">Similarity and Similarity Measures Chain Method of Clustering Clustering Criterion Functions Iterative Optimization Clustering procedure – basic min. squared error K-means Clustering Hierarchical Clustering Mixture Densities: Gaussian Mixtures Component Analysis: PCA, ICA</summary></entry><entry><title type="html">[MLPR #] Unsupervised Classification 1 (fisher)</title><link href="https://shvtr159.github.io/mlpr/mlpr-unsupervised-classification-1/" rel="alternate" type="text/html" title="[MLPR #] Unsupervised Classification 1 (fisher)" /><published>2021-12-04T00:00:00+09:00</published><updated>2021-12-04T00:00:00+09:00</updated><id>https://shvtr159.github.io/mlpr/mlpr-unsupervised-classification-1</id><content type="html" xml:base="https://shvtr159.github.io/mlpr/mlpr-unsupervised-classification-1/">&lt;p&gt;Supervised 에서는 data에 label도 있고 전체 class의 갯수를 알 수 있기때문에 data로부터 그 분포를 추정할 수 있었다. unsupervised classification은 이러한 정보가 없을 때 data를 구분하는 방법이다. 
Unknown targets를 분류하는 방법에는 다양한 방법이 있는데 다음과 같은 방법이 있다.&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Criterion function 방법 : Sum of squared error, Min. variance, Scatter matrices, Optimization problem&lt;/li&gt;
  &lt;li&gt;Heuristic 방법 : Chain, Hierarchical, Min. spanning tree&lt;/li&gt;
  &lt;li&gt;Unmixing 방법 : Gaussian mixture, PCA, ICA&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;앞으로 다음 순서로 진행하며 unsupervised classification 방법에 대해 알아본다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Similarity and Similarity Measures&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Chain Method of Clustering&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Clustering Criterion Functions&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;Iterative Optimization&lt;/li&gt;
  &lt;li&gt;Clustering procedure – basic min. squared error&lt;/li&gt;
  &lt;li&gt;K-means Clustering&lt;/li&gt;
  &lt;li&gt;Hierarchical Clustering&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;여기까지는 Non-statistical한 방법이고, 이후 두 주제는 statistical한 방법이다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Mixture Densities: Gaussian Mixtures&lt;/li&gt;
  &lt;li&gt;Component Analysis: PCA, ICA&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;similarity-and-similarity-measures&quot;&gt;Similarity and Similarity Measures&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/79836443/146315768-90f03044-8073-4775-8140-9664492d7648.png&quot; alt=&quot;image&quot; width=&quot;40%&quot; height=&quot;40%&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;위 이미지는 2차 statistical(평균과 공분산)이 모두 같지만 smaple의 분포는 모두 다르다. 이를 분포의 혼합으로 만들어진다고 가정하면 근사화할 수 있겠지만 쉬운 작업은 아니다. 이러한 이유로 clustering을 사용하곤 한다. 그러나 clustering된 sample간의 유사성이나 분류를 평가하기 위해서는 측정 방법이 필요하다.&lt;/p&gt;

&lt;p&gt;클러스터링 결과를 Euclidean distance를 이용하여 측정하게 된다면 feature space에서의 translationis이나 rotation과 같은 변환에는 결과에 차이가 없지만, 일반적으로 scaling과 같은 선형 변환에 따라 결과가 변형되기 때문에 조심해야한다.&lt;/p&gt;

&lt;p&gt;다른 similarity  측정 방법&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Angular Similarity&lt;/strong&gt;&lt;br /&gt;
nonmetric similarity function으로 $S(x_i,x_j)=x_i^Tx_j/\left |x_i  \right |\left |x_j \right |$ (normalized 내적, $x_i$와 $x_j$사이 각의 코사인 값). 두 vector 사이의 각이 의미가 있을때 유용하다.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Binary Similarity&lt;/strong&gt;&lt;br /&gt;
$S(x_i,x_j)=x_i^Tx_i+x_j^Tx_j-x_i^Tx_j$로 계산된다. $x_i^Tx_j$는 공통으로 나타나는 feature의 개수로 결국 $S$는공통으로 나타내는 feature의 비율이다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;chain-method-of-clustering&quot;&gt;Chain Method of Clustering&lt;/h2&gt;
&lt;ol&gt;
  &lt;li&gt;첫번째 sample을 cluster #1 ($S_1$)으로 할당한다.&lt;/li&gt;
  &lt;li&gt;다음 sample과 지금 sample간의 거리 $d$를 계산하고  $d_0$(미리 정해둔 threshold)와 비교한다. 만약 $d&amp;lt;d_0$이면 sample을 같은 cluster로 분류하고, 반대의 경우 새로운 cluster를 생성한다.&lt;/li&gt;
  &lt;li&gt;다음 sample도 존재하는 모든 cluster와의 거리 $d$를 계산하고 최소값을 찾는다. 만약 $d_{min}&amp;lt;d_{0}$이면 해당 cluster로 분류하고 반대의 경우 이전과 같이 새로운 cluster를 생성한다.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;이때, $d$는 해당 cluster의 첫번째 sample과의 거리로 계산하거나 cluster의 sample mean과의 거리로 계산한다. 그러나 이 방법은 $d_0$와 sample의 차수에 sensitive하다는 문제점이 있다.&lt;/p&gt;

&lt;h2 id=&quot;clustering-criterion-functions&quot;&gt;Clustering Criterion Functions&lt;/h2&gt;
&lt;p&gt;Clustering을 수행하고 나면 clustering이 잘 되었는지 확인해야 한다. 그래서 criterion fucntion을 사용해 이 function을 최소화하거나 최대화하는 값을 찾아 좋은 clustering을 선택한다. 앞으로 사용할 표기를 먼저 정의한다.&lt;/p&gt;

&lt;p&gt;$J$개의 sample $x_1, …, x_j$의 집합 $z$를 $K$개의 subset $z_1, z_2, …, z_k$로 나눈다. 이 $K$개의 집합들의 $J$개의 sample들의 cluster quality를 평가한다.&lt;/p&gt;
&lt;h3 id=&quot;1-sum-of-squared-error-criterion&quot;&gt;1. Sum of Squared Error Criterion&lt;/h3&gt;
&lt;p&gt;가장 간단하면서도 널리 쓰이는 방법으로 cluster의 평균과 그 sample들간의 거리의 차의 제곱을 모두 합한다.&lt;/p&gt;

\[J_e=\sum^K_{i=1}{\sum_{x_j\in z_i}\left \| x_j-m_i \right \|^2}\]

&lt;p&gt;$m_i$는 $z_i$의 sample들의 평균. Sum square error는 $J_e$값이 최소가 될때 최소의 variance를 가지므로 이때 cloud가 compact하고 각각 잘 분리된 좋은 cluster라고 이야기 할 수 있다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/79836443/146320721-d69de763-7cc4-4a4f-97d9-7949a3bf2128.png&quot; alt=&quot;image&quot; width=&quot;40%&quot; height=&quot;40%&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;그러나 위 이미지와 같이 분포가 다른 경우 잘못된 clustering을 수행할 수도 있다.&lt;/p&gt;

&lt;h3 id=&quot;2-minimum-variance-criteria&quot;&gt;2. Minimum-Variance Criteria&lt;/h3&gt;
&lt;p&gt;이 방법은 cluster의 모든 sample들간의 평균 제곱 거리를 이용한다.&lt;/p&gt;

\[J_e=\frac{1}{2}\sum^K_{i=1}J_i\bar{s}_ i\]

\[\bar{s}_ i=\frac{1}{J_i^2}\sum_{x_j\in z_i}{\sum_{x_l\in z_i}\left \| x_j-x_l \right \|^2}\]

&lt;p&gt;$\bar{s}_ i$의 다른 방법으로는  $\left | x_j-x_l \right |^2$ 대신 $s(x_j,x_l)$($s$는 similarity function)을 사용하거나 전체 합 대신 최소값을 사용하여 $\bar{s}_ i=\min_{x_j,x_l\in z_i}[s(x_j,x_l)]$을 사용하는 방법도 있다.&lt;/p&gt;

&lt;h3 id=&quot;3-scattering-criteria&quot;&gt;3. Scattering Criteria&lt;/h3&gt;
&lt;p&gt;Scatter matrix로부터 sample의 scattering을 측정한다. 여기에 사용되는 mean vector와 scatter matrix에는 다음이 있다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/79836443/146324824-0ddcbd07-8698-4076-9c66-836647f71f62.png&quot; alt=&quot;image&quot; width=&quot;90%&quot; height=&quot;90%&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;전체 scatter matrix$S_T$는 within-cluster(클러스터 내) scatter matrix$S_W$와 Between-cluster(클러스터 간) scatter matrix$S_B$의 합으로 이루어진다. Scatter의 양에 관해 더 정확하게 하기위해 scatter matrix의 크기의 Scalar 측정을 필요로 한다. 이 측정에는 3가지 기준이 있다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Trace 기준&lt;/strong&gt;&lt;br /&gt;
대략적으로 trace는 좌표 방향들에서 분산들의 합의 비례하기 대문에 scattering 반경의 제곱을 측정한다.&lt;/li&gt;
&lt;/ul&gt;

\[Tr\{S_W\}=\sum^K_{i=1}{Tr\{S_i\}}=\sum^K_{i=1}\sum_{x_j\in z_i}{\left \| x_j-m_i \right \|^2}\]

\[Tr\{S_B\}=\sum^K_{i=1}J_i{\left \| m_i-m \right \|^2}\]

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Determinant 기준&lt;/strong&gt;&lt;br /&gt;
Determinant는 main axis들의 방향에서 분산들의 곱에 비례하므로, scattering volume의 제곱을 측정한다.&lt;/li&gt;
&lt;/ul&gt;

\[J_d=\left |S_W\right |=\sum^K_{i=1}{\left |S_i\right |}\]

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Invariant 기준 (불변적 기준)&lt;/strong&gt;&lt;br /&gt;
$\lambda_n$는 $S_W^{-1}S_B$의 n번째 eigenvalue이고 이는 lineartransformation에 불변하다.&lt;/li&gt;
&lt;/ul&gt;

\[J_f=Tr\{S_W^{-1}S_B\}=\sum^N_{n=1}{\lambda_n}\]

&lt;h2 id=&quot;fishers-linear-discriminent&quot;&gt;Fisher’s Linear Discriminent&lt;/h2&gt;</content><author><name>KYG</name></author><category term="MLPR" /><summary type="html">Supervised 에서는 data에 label도 있고 전체 class의 갯수를 알 수 있기때문에 data로부터 그 분포를 추정할 수 있었다. unsupervised classification은 이러한 정보가 없을 때 data를 구분하는 방법이다. Unknown targets를 분류하는 방법에는 다양한 방법이 있는데 다음과 같은 방법이 있다. Criterion function 방법 : Sum of squared error, Min. variance, Scatter matrices, Optimization problem Heuristic 방법 : Chain, Hierarchical, Min. spanning tree Unmixing 방법 : Gaussian mixture, PCA, ICA</summary></entry><entry><title type="html">[MLPR #] Nonparameteric Estimation 1 (미완)</title><link href="https://shvtr159.github.io/mlpr/mlpr-nonparametric-estimation/" rel="alternate" type="text/html" title="[MLPR #] Nonparameteric Estimation 1 (미완)" /><published>2021-12-03T00:00:00+09:00</published><updated>2021-12-03T00:00:00+09:00</updated><id>https://shvtr159.github.io/mlpr/mlpr-nonparametric-estimation</id><content type="html" xml:base="https://shvtr159.github.io/mlpr/mlpr-nonparametric-estimation/">&lt;p&gt;이전까지 확률을 이용해 density function을 추정했다면 Nonparameteric Technique는 math form 없이 density를 추정한다.&lt;/p&gt;

&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;

&lt;h2 id=&quot;estimation-procedure&quot;&gt;Estimation Procedure&lt;/h2&gt;
&lt;p&gt;$x$의 density를 추정하기 위한 절차를 알아보자&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;영역 $R_1, R_2, …$을 생성한다.&lt;/li&gt;
  &lt;li&gt;이때 영역 $R_j$는 j개의 sample들로 구성된다. ??&lt;/li&gt;
  &lt;li&gt;$R_j$의 크기를 $V_j$라고 한다&lt;/li&gt;
  &lt;li&gt;$R_j$에 속해있는 sample들의 개수를 $k_j$라고 한다&lt;/li&gt;
  &lt;li&gt;$p(x)$의 j번째 추정은 $p_j(x)=[k_j/j]/V_j$이다. $p_j(x)$는 다음과 같은 경우에 $p(x)$에 수렴한다.&lt;br /&gt;
 (1) $\lim_{j\to\infty}V_j=0$&lt;br /&gt;
 (2) $\lim_{j\to\infty}k_j=\infty$&lt;br /&gt;
 (3) $\lim_{j\to\infty}k_j/j=0$&lt;br /&gt;
위 조건을 만족하는 방법 두가지&lt;/li&gt;
  &lt;li&gt;영역의 크기를 축소시켜가는것. $V_j=1/\sqrt{j}$ (Parzen window)&lt;/li&gt;
  &lt;li&gt;$k_j=\sqrt{j}$로 설정하여 $x$ 주변 $k_j$개의 sample을 포함할때까지 크기를 증가시키는 것. (nearest neighbor)&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;two-popular-techniques&quot;&gt;Two Popular Techniques&lt;/h2&gt;
&lt;h3 id=&quot;1-parzen-window-estimation&quot;&gt;1) Parzen Window Estimation&lt;/h3&gt;
&lt;p&gt;window function은 $\Delta(\underline{u})=\Delta(\underline{x}-\underline{x}_ i)$로 정의한다($\underline{x}_ i$가 중심이 된다).&lt;/p&gt;

&lt;h3 id=&quot;2-k-nearest-neighbor&quot;&gt;2) K Nearest Neighbor&lt;/h3&gt;</content><author><name>KYG</name></author><category term="MLPR" /><summary type="html">이전까지 확률을 이용해 density function을 추정했다면 Nonparameteric Technique는 math form 없이 density를 추정한다.</summary></entry><entry><title type="html">[MLPR #] Parameter Estimation 2 (미완)</title><link href="https://shvtr159.github.io/mlpr/mlpr-parameter-estimation-2/" rel="alternate" type="text/html" title="[MLPR #] Parameter Estimation 2 (미완)" /><published>2021-12-02T00:00:00+09:00</published><updated>2021-12-02T00:00:00+09:00</updated><id>https://shvtr159.github.io/mlpr/mlpr-parameter-estimation%202</id><content type="html" xml:base="https://shvtr159.github.io/mlpr/mlpr-parameter-estimation-2/">&lt;p&gt;Parameter Estimation 1에서 추정 방법중 Maximum likelihood에 대해 알아보았다. 2에서는 나머지 한가지 방법인 Maximum a Posterior (MAP) estimation에 대해서 알아본다.
MLPR 11~13&lt;/p&gt;</content><author><name>KYG</name></author><category term="MLPR" /><summary type="html">Parameter Estimation 1에서 추정 방법중 Maximum likelihood에 대해 알아보았다. 2에서는 나머지 한가지 방법인 Maximum a Posterior (MAP) estimation에 대해서 알아본다. MLPR 11~13</summary></entry><entry><title type="html">[MLPR #] Parameter Estimation 1 (미완)</title><link href="https://shvtr159.github.io/mlpr/mlpr-parameter-estimation/" rel="alternate" type="text/html" title="[MLPR #] Parameter Estimation 1 (미완)" /><published>2021-12-01T00:00:00+09:00</published><updated>2021-12-01T00:00:00+09:00</updated><id>https://shvtr159.github.io/mlpr/mlpr-parameter-estimation</id><content type="html" xml:base="https://shvtr159.github.io/mlpr/mlpr-parameter-estimation/">&lt;p&gt;이전까지는 모든 statistics과 probability(prior probabiliteis, class-conditional densities(likelihood) 등)를 알 때 Bayes Classifier를 이용해 data가 어디에 속하는지 분류할 수 있었다. 그러나 이렇게 모든 statistics를 아는 상황은 드물기 때문에 data로부터 이를 추정해야만 한다. priori를 모른다고 가정할 때 다음 두 technique를 이용하여 $p(x\mid S_{i})$를 추정할 수 있다.&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Parametric&lt;/strong&gt; : $p(x\mid S_{i})$의 form을 알거나, 안다고 가정할 때 함수의 parameter를 추정한다. 예를 들어$p(x\mid S_{i})=N(x,m_i,\Sigma_i)$인 Gaussian 함수라고 할 때, training sample로부터 $m_i,\Sigma_i$를 추정하는 것이다. 이 방법에는 &lt;strong&gt;Maximum likelyhood estimation(최대 우도 추정)&lt;/strong&gt; 과 &lt;strong&gt;Maximum a Posterior (MAP) estimation(최대 사후 확률 추정)&lt;/strong&gt; (Bayesian estimation)이 있다.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Nonparametric&lt;/strong&gt; : density에 대한 정보도 없이 data만 있을때로 data로부터 density function을 추정한다.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;ML과 Bayesian의 주된 차이점은 ML는 paramter가 확실히 정해져 있지만 우리가 모르고 있다는 관점이고, bayesian은 parameter 자체를 random variable로 본다. bayesian learning은 parameter의 true value와 가까울수록 peak값에 가까워지므로 추가적인 sample이 들어오면 더 좋은 posteriori density로 update할 수 있다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/79836443/146154164-1aed9de4-b178-421d-849e-d147df19da1a.png&quot; alt=&quot;image&quot; width=&quot;40%&quot; height=&quot;40%&quot; /&gt;
&lt;img src=&quot;https://user-images.githubusercontent.com/79836443/146154305-28796a2e-df6c-429c-9c83-3ed53da102f3.png&quot; alt=&quot;image&quot; width=&quot;55%&quot; height=&quot;55%&quot; /&gt;&lt;center&gt;&lt;span style=&quot;color:rgb(150, 150, 150)&quot;&gt;Left: ML. true에 가까울수록 높다. / Right: MAP. sample이 많아질수록 peak에 가까워진다.&lt;/span&gt;&lt;/center&gt;&lt;/p&gt;
&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;해당 방법들에 대해 알아보기 전에 추정에 대해 간단히 알아본다.&lt;/p&gt;

&lt;p&gt;먼저 $\underline{\theta }$를 고정돼있지만 우리가 지금 모르는 parameter들의 vector라고 하자(ex. 평균 or 분산). 그리고 $\hat{\underline{\theta }}$은 $\underline{\theta }$의 추정값이라고 한다. $\underline{\theta }$는 결정되어있고, $\hat{\underline{\theta }}$는 random하다.&lt;/p&gt;

&lt;p&gt;또, $x_1, x_2, …$를 우리가 추정할 density로부터 추출한 random sample vector라고 한다. 각각의 $x_i$들은 iid(independent, identically, distributed)하다고 가정한다.&lt;/p&gt;

&lt;p&gt;이제 $\underline{z}=[x_1, x_2, … , x_J]$라 하면, $\hat{\underline{\theta }}=G(x_1, x_2, … , x_J)=G(\underline{z})=\hat{\underline{\theta }}(z)$으로 어떤한 process $G$를 수행하여 랜덤한 추정값을 얻게 되는 것이다.&lt;/p&gt;

&lt;h3 id=&quot;좋은-추정값의-특성&quot;&gt;좋은 추정값의 특성&lt;/h3&gt;
&lt;h4 id=&quot;1-unbiased-estimate&quot;&gt;1. Unbiased estimate&lt;/h4&gt;
&lt;p&gt;가장 중요한 성질. 기대값 $E(\hat{\theta})=\theta$이면 이를 unbiased estimate라고 한다. 표본 평균은 unbiased estimate이나 표본 분산은 biased estimate 이다.&lt;/p&gt;

&lt;h4 id=&quot;2-consistent-estimate&quot;&gt;2. Consistent estimate&lt;/h4&gt;
&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/79836443/146173297-87140ccb-0add-4190-b829-e5e1c7e5e974.png&quot; alt=&quot;image&quot; class=&quot;align-center&quot; /&gt;
표본의 크기가 커질수록 추정값이 실제 값 $\underline{\theta}$에 가까워지는 성질.&lt;/p&gt;

&lt;h4 id=&quot;3-efficient-estimate&quot;&gt;3. Efficient estimate&lt;/h4&gt;
&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/79836443/146173820-90aed70d-1f20-41f9-9bab-e8f935a54d68.png&quot; alt=&quot;image&quot; class=&quot;align-center&quot; /&gt;
추정값의 분산이 작게 나타나는 성질으로 추정값의 분산이 작을수록 더  efficient하다고 할 수 있다.&lt;sup&gt;&lt;a href=&quot;#footnote_1&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;

&lt;h4 id=&quot;4-sufficient-estimate&quot;&gt;4. Sufficient estimate&lt;/h4&gt;
&lt;p&gt;추정값이 $\underline{\theta}$에 대해 많은 정보를 포함하는지에 대한 성질.&lt;/p&gt;

&lt;h2 id=&quot;maximum-likelihood&quot;&gt;Maximum-Likelihood&lt;/h2&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;a name=&quot;footnote_1&quot;&gt;1&lt;/a&gt;: 이미지 출처 : 정보통신기술용어해설 http://www.ktword.co.kr/test/view/view.php?m_temp1=458&lt;br /&gt;&lt;/p&gt;</content><author><name>KYG</name></author><category term="MLPR" /><summary type="html">이전까지는 모든 statistics과 probability(prior probabiliteis, class-conditional densities(likelihood) 등)를 알 때 Bayes Classifier를 이용해 data가 어디에 속하는지 분류할 수 있었다. 그러나 이렇게 모든 statistics를 아는 상황은 드물기 때문에 data로부터 이를 추정해야만 한다. priori를 모른다고 가정할 때 다음 두 technique를 이용하여 $p(x\mid S_{i})$를 추정할 수 있다. Parametric : $p(x\mid S_{i})$의 form을 알거나, 안다고 가정할 때 함수의 parameter를 추정한다. 예를 들어$p(x\mid S_{i})=N(x,m_i,\Sigma_i)$인 Gaussian 함수라고 할 때, training sample로부터 $m_i,\Sigma_i$를 추정하는 것이다. 이 방법에는 Maximum likelyhood estimation(최대 우도 추정) 과 Maximum a Posterior (MAP) estimation(최대 사후 확률 추정) (Bayesian estimation)이 있다. Nonparametric : density에 대한 정보도 없이 data만 있을때로 data로부터 density function을 추정한다.</summary></entry><entry><title type="html">[MLPR #] Bayes Classifiers</title><link href="https://shvtr159.github.io/mlpr/mlpr-bayes-classifiers/" rel="alternate" type="text/html" title="[MLPR #] Bayes Classifiers" /><published>2021-10-26T00:00:00+09:00</published><updated>2021-10-26T00:00:00+09:00</updated><id>https://shvtr159.github.io/mlpr/mlpr-bayes-classifiers</id><content type="html" xml:base="https://shvtr159.github.io/mlpr/mlpr-bayes-classifiers/">&lt;p&gt;discriminant decision $g_i(\underline{x})$를 이용하여 모든 $i \neq j$에 대해 $g_i(\underline{x})&amp;gt;g_j(\underline{x})$ 분류를 사용한다. 이를 probability term으로 표현하면&lt;/p&gt;

\[g_i(\underline{x})=p(S_i \mid \underline{x})\]

\[\rightarrow \; g_i(\underline{x})=p(\underline{x} \mid S_i)P(S_i)\]

\[\rightarrow \; g_i(\underline{x})=\textup{ln}(p(\underline{x} \mid S_i))+\textup{ln}(P(S_i))\]

&lt;h2 id=&quot;normal-density&quot;&gt;Normal Density&lt;/h2&gt;</content><author><name>KYG</name></author><category term="MLPR" /><summary type="html">discriminant decision $g_i(\underline{x})$를 이용하여 모든 $i \neq j$에 대해 $g_i(\underline{x})&amp;gt;g_j(\underline{x})$ 분류를 사용한다. 이를 probability term으로 표현하면</summary></entry><entry><title type="html">[MLPR #] Bayes Decision Classification</title><link href="https://shvtr159.github.io/mlpr/mlpr-statistical-cassification1/" rel="alternate" type="text/html" title="[MLPR #] Bayes Decision Classification" /><published>2021-10-23T00:00:00+09:00</published><updated>2021-10-23T00:00:00+09:00</updated><id>https://shvtr159.github.io/mlpr/mlpr-statistical-cassification1</id><content type="html" xml:base="https://shvtr159.github.io/mlpr/mlpr-statistical-cassification1/">&lt;p&gt;Bayes Decision Theory : 이 방식은 모든 확률 값들을 알고 있다고 가정한다(평균, 분산 등).&lt;/p&gt;
&lt;h2 id=&quot;bayes-formula&quot;&gt;Bayes Formula&lt;/h2&gt;

\[P(S\mid x)=\frac{P(x\mid S)P(S_k)}{P(x)}\]

&lt;ul&gt;
  &lt;li&gt;$P(S\mid x)$ : posterior probability (사후 확률)&lt;/li&gt;
  &lt;li&gt;$P(x\mid S)$ : likelihood (우도, 가능도)&lt;/li&gt;
  &lt;li&gt;$P(S)$ : prior probability (사전 확률)&lt;/li&gt;
  &lt;li&gt;$P(x)$ : Evidence&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;bayes-decision-rule-for-최소-error-2-class&quot;&gt;Bayes Decision Rule for 최소 Error (2-class)&lt;/h2&gt;

\[\begin{matrix}
p(S_1\mid \underline{x})&amp;gt;p(S_2\mid \underline{x})\rightarrow \underline{x}\in S_1 \\ \\
p(S_1\mid \underline{x})&amp;lt;p(S_2\mid \underline{x})\rightarrow \underline{x}\in S_2
\end{matrix}\]

&lt;p&gt;즉, x는 두 class 중 확률이 더 높은 class에 속한다고 판단한다. 이를 Bayes Theorem을 이용하여 바꾸면&lt;/p&gt;

&lt;h3 id=&quot;decision-rule&quot;&gt;Decision Rule&lt;/h3&gt;

\[\begin{matrix}
p(\underline{x} \mid S_1)p(S_1)&amp;gt;p(\underline{x} \mid S_2)p(S_2) \rightarrow \underline{x}\in S_1 \\ \\
p(\underline{x} \mid S_1)p(S_1)&amp;lt;p(\underline{x} \mid S_2)p(S_2) \rightarrow \underline{x}\in S_2
\end{matrix}\]

&lt;p&gt;으로 표현되고 다음과 같이 다시 정리할 수 있다.&lt;/p&gt;

\[\frac{p(\underline{x} \mid S_1)}{p(\underline{x} \mid S_2)}\quad\begin{matrix}
\underline{x}\in S_1\\ 
&amp;gt;\\ 
&amp;lt;\\ 
\underline{x}\in S_2
\end{matrix}\quad \frac{P(S_1)}{P(S_2)}\]

&lt;p&gt;이 때, $l(x) = \frac{p(\underline{x} \mid S_1)}{p(\underline{x} \mid S_2)}$를 likelihood ratio(우도 비), $\frac{P(S_1)}{P(S_2)} = T$를 threshold value 라고 한다.&lt;/p&gt;

&lt;p&gt;위 정리된 식은 Log를 취해 *를 +로 바꿔 cost를 크게 줄일 수 있고, 다음과 같이 변경된다.&lt;/p&gt;

\[h(\underline{x})=-\textup{ln}(l(\underline{x}))=\textup{ln}(p(\underline{x} \mid S_2))-\textup{ln}(p(\underline{x} \mid S_1))&amp;lt;\textup{ln}(\frac{P(S_1)}{P(S_2)})\quad \Rightarrow \; \underline{x}\in S_1\]

&lt;h3 id=&quot;probability-of-error&quot;&gt;Probability of Error&lt;/h3&gt;
&lt;p&gt;이는 error region을 integrate 하는 형식으로 구해진다. 2 class의 경우&lt;/p&gt;

\[P_e=p(S_1)\int_{\Gamma_2}p(\underline{x} \mid S_1)dx+p(S_2)\int_{\Gamma_1}p(\underline{x} \mid S_2)dx\]

&lt;p&gt;이며 다중 class의 경우 $P_e=1-P(correct)$ 으로 알기 쉽게 표현할 수 있다. 이때, $P(correct)$ 은 $\sum_{i=1}^{K}\int_{\Gamma_i}p(\underline{x} \mid S_i)P(S_i)d\underline{x}$ 이다.&lt;/p&gt;
&lt;h2 id=&quot;bayes-decision-rule-for-최소-risk-2-class&quot;&gt;Bayes Decision Rule for 최소 Risk (2-class)&lt;/h2&gt;
&lt;p&gt;Bayes minimun error를 일반화 한다. $C(S_k \mid S_j)$를 $\underline{x}$가 $S_j$인데 $S_k$로 판별했을 때의 cost라고 하자. 그리고 이는 간단히 $C_{kj}=C(S_k \mid S_j)$로 표기한다(책에서는 $C_{kj}$ 대신 $\lambda_{kj}$로 표현하였다). 일반적으로 틀렸을 때 초래되는 손실은 맞을 때보다 더 크므로 $C_{21}&amp;gt;C_{11}$, $C_{12}&amp;gt;C_{22}$이다. 이를 한번에 matrix로 다음과 같이 표기한다.&lt;/p&gt;

\[\underline{C}=\begin{bmatrix}
C_{11} &amp;amp; C_{12}\\ 
C_{21} &amp;amp; C_{22}
\end{bmatrix}\]

&lt;p&gt;이때, 조건부 평균 risk (conditional avarage loss or risk) $R(S_k \mid \underline{x})$이고 2 class 에서 이 식은 모든 class의 값을 합한&lt;/p&gt;

\[\begin{matrix}
R(S_1 \mid \underline{x})=C(S_1 \mid S_1)P(S_1 \mid \underline{x})+C(S_1 \mid S_2)P(S_2 \mid \underline{x})\\ 
R(S_2 \mid \underline{x})=C(S_2 \mid S_1)P(S_1 \mid \underline{x})+C(S_2 \mid S_2)P(S_2 \mid \underline{x})
\end{matrix}\]

&lt;p&gt;이며, Decision cule은 total expected risk를 최소화 하기위한 action으로 다음과 같다.&lt;/p&gt;

\[R=\int_{\Gamma_1}R(S_1 \mid \underline{x})p(x)d\underline{x}+\int_{\Gamma_2}R(S_2 \mid \underline{x})p(x)d\underline{x}\]

&lt;p&gt;여기서 R을 최소화하기 위해 각 $\underline{x}$에 대한 $R(S_k \mid \underline{x})$이 최소화되는 영역으로 선택한다(Risk는 작을수록 좋으므로).&lt;/p&gt;

\[\begin{matrix}
R(S_1 \mid \underline{x}) &amp;lt; R(S_2 \mid \underline{x}) \rightarrow S_1 \\ 
R(S_1 \mid \underline{x}) &amp;gt; R(S_2 \mid \underline{x}) \rightarrow S_2 
\end{matrix}\]

&lt;h3 id=&quot;decision-rule-minimum-risk-classifier&quot;&gt;Decision Rule (Minimum Risk Classifier)&lt;/h3&gt;

\[R(S_1 \mid \underline{x}) \; \begin{matrix}
S_1\\ 
&amp;lt;\\ 
&amp;gt;\\ 
S_2
\end{matrix}\; R(S_2 \mid \underline{x})\]

&lt;p&gt;이를 다시 이전의 $C$를 이용한 식으로 바꾸면&lt;/p&gt;

\[C_{11}P(S_1 \mid \underline{x})+C_{12}P(S_2 \mid \underline{x}) \quad \begin{matrix}
&amp;lt;\\ 
&amp;gt;
\end{matrix}\; C_{21}P(S_1 \mid \underline{x})+C_{22}P(S_2 \mid \underline{x})\]

&lt;p&gt;이고, 같은 $P$끼리 정리하여 묶어낸 뒤 $P(S_k\mid x)=\frac{P(S_k)P(x\mid S_k)}{P(x)}$ 로 바꿔 쓴 뒤, likelihood ratio가 나타나도록 정리하면 최종적으로 다음 식이 된다.&lt;/p&gt;

\[l(\underline{x})=\frac{p(\underline{x} \mid S_1)}{p(\underline{x} \mid S_2)}\quad \begin{matrix}
&amp;gt;\\ 
&amp;lt;\\ 
\end{matrix}\quad \frac{(C_{12}-C_{22})P(S_2)}{(C_{21}-C_{11})P(S_1)}\]

&lt;p&gt;이때, 만약 $C_{11}=0, C_{12}=1, C_{21}=1,C_{22}=0$ 이면 다음과 같은 형태의 &lt;strong&gt;Bayes minimum error rule&lt;/strong&gt;이 된다.&lt;/p&gt;

\[l(\underline{x})=\frac{p(\underline{x} \mid S_1)}{p(\underline{x} \mid S_2)}\; \begin{matrix}
&amp;gt;\\ 
&amp;lt;\\ 
\end{matrix}\; \frac{P(S_2)}{P(S_1)}\]

&lt;h2 id=&quot;bayes-minimum-error-and-minimum-risk-다중-class&quot;&gt;Bayes Minimum Error and Minimum Risk (다중 class)&lt;/h2&gt;
&lt;h3 id=&quot;bayes-minimum-error--multiple-classes&quot;&gt;Bayes Minimum Error – Multiple Classes&lt;/h3&gt;
&lt;p&gt;모든 $i \neq j$에 대해 $P(S_i \mid \underline{x} )&amp;gt;P(S_j \mid \underline{x})$ 이면 $\underline{x}\in S_i$ 이다. 다시 변경하면, 모든 $i \neq j$에 대해 $p(\underline{x} \mid S_i)p(S_i)&amp;gt;p(\underline{x} \mid S_j)p(S_j)$ 이면 $\underline{x}\in S_i$ 이다. Discriminant function은 다음과 같다.&lt;/p&gt;

\[g_i(\underline{x})=p(\underline{x} \mid S_i)p(S_i)\]

&lt;h3 id=&quot;bayes-minimum-risk--multiple-classes&quot;&gt;Bayes Minimum Risk – Multiple Classes&lt;/h3&gt;
&lt;p&gt;$R(S_k \mid \underline{x})=\sum_{i=1}^{K}C_{ki}P(S_i\mid \underline{x})$를 conditional loss로 변경하면 $R(S_k \mid \underline{x})=\sum_{i=1}^{K}C_{ki}P(\underline{x} \mid S_i)P(S_i)$ 이다. 만약, 모든 $i \neq j$에 대해 $R_c(S_i \mid \underline{x})&amp;lt;R_c(S_j \mid \underline{x})$ 이면 $\underline{x}\in S_i$ 이다. Discriminant function은 다음과 같다.&lt;/p&gt;

\[g_k(\underline{x})=-R_c(S_k \mid \underline{x})\]

&lt;p&gt;’$-$’를 곱해주는 이유는 위의 표현처럼 $g_i(\underline{x})&amp;gt;g_j(\underline{x})$ 를 유지하기 위해서 이다.&lt;/p&gt;

&lt;p&gt;$R_c$ 식은 다음과 같이 행렬식의 곱 형태로 나타낼 수 있고 이 경우 2가지 special case를 확인하기에 편리하다.&lt;/p&gt;

\[R_c(S_k \mid \underline{x})=\begin{bmatrix}
C_{11} &amp;amp; C_{12} &amp;amp; \cdots\\ 
C_{21}&amp;amp; \ddots  &amp;amp; \\ 
\cdots  &amp;amp;  &amp;amp; C_{kk}
\end{bmatrix}\begin{bmatrix}
p(\underline{x} \mid S_1)P(S_1)\\ 
p(\underline{x} \mid S_2)P(S_2)\\ 
\cdots
\end{bmatrix}\]

&lt;ol&gt;
  &lt;li&gt;special case 1 : Symmetric 0-1 cost function&lt;/li&gt;
  &lt;li&gt;special case 2 : Diagonal Cost Function&lt;/li&gt;
&lt;/ol&gt;</content><author><name>KYG</name></author><category term="MLPR" /><summary type="html">Bayes Decision Theory : 이 방식은 모든 확률 값들을 알고 있다고 가정한다(평균, 분산 등). Bayes Formula</summary></entry><entry><title type="html">[MLPR #1] Introduction</title><link href="https://shvtr159.github.io/mlpr/mlpr-1-notation/" rel="alternate" type="text/html" title="[MLPR #1] Introduction" /><published>2021-10-20T00:00:00+09:00</published><updated>2021-10-20T00:00:00+09:00</updated><id>https://shvtr159.github.io/mlpr/mlpr-1-notation</id><content type="html" xml:base="https://shvtr159.github.io/mlpr/mlpr-1-notation/">&lt;h2 id=&quot;notation&quot;&gt;Notation&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;$\underline{ \textbf{x}}$ : data 벡터&lt;/li&gt;
  &lt;li&gt;prototypes:
    &lt;ul&gt;
      &lt;li&gt;$\underline{y}_ m^{(k)}$ : class $S_ {k}$에 속한 m번째 prototype&lt;/li&gt;
      &lt;li&gt;k = class index&lt;/li&gt;
      &lt;li&gt;$m_k$ = $S_ {k}$에 있는 prototype들의 번호&lt;/li&gt;
      &lt;li&gt;$\underline{y}_ m^{(k)}$, m = 1,2, … , $m_k$ 는  class $S_ {k}$의 모든 prototype로 정의&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;classification&quot;&gt;Classification&lt;/h2&gt;
&lt;p&gt;각각의 Class를 나누기 위해서는 Decision Rule이 결정되어야 한다. 예를 들어 변수 값에 따라 분류 할 때, 값이 5.5 초과면 $S_ {1}$, 이하면 $S_ {2}$로 분류할 수 있다. 그러나 이러한 feature가 1개일때보다는 2개일때 더 정확한 분류를 할 수 있고, 더 많아질수록 더 정확히 분류할 수 있다. 이렇게 fature의 차원이 커짐에 따라 decision surface의 차원도 점, 선, 면 으로 점점 증가하게 된다.&lt;/p&gt;

&lt;p&gt;이렇게 나눠진 많은 Class들 중 $\underline{ \textbf{x}}$ 가 어디에 속하는 지 알기 위해서는 해당 class와 $\underline{ \textbf{x}}$의 거리를 측정해야 한다.&lt;/p&gt;</content><author><name>KYG</name></author><category term="MLPR" /><summary type="html">Notation $\underline{ \textbf{x}}$ : data 벡터 prototypes: $\underline{y}_ m^{(k)}$ : class $S_ {k}$에 속한 m번째 prototype k = class index $m_k$ = $S_ {k}$에 있는 prototype들의 번호 $\underline{y}_ m^{(k)}$, m = 1,2, … , $m_k$ 는 class $S_ {k}$의 모든 prototype로 정의</summary></entry></feed>