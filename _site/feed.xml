<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.2.0">Jekyll</generator><link href="https://shvtr159.github.io/feed.xml" rel="self" type="application/atom+xml" /><link href="https://shvtr159.github.io/" rel="alternate" type="text/html" /><updated>2021-12-16T17:43:54+09:00</updated><id>https://shvtr159.github.io/feed.xml</id><title type="html">Study Blog</title><subtitle>for study</subtitle><author><name>KYG</name></author><entry><title type="html">[MLPR #] Unsupervised Classification 2 (미완)</title><link href="https://shvtr159.github.io/mlpr/mlpr-unsupervised-classification-2/" rel="alternate" type="text/html" title="[MLPR #] Unsupervised Classification 2 (미완)" /><published>2021-12-05T00:00:00+09:00</published><updated>2021-12-05T00:00:00+09:00</updated><id>https://shvtr159.github.io/mlpr/mlpr-unsupervised-classification-2</id><content type="html" xml:base="https://shvtr159.github.io/mlpr/mlpr-unsupervised-classification-2/">&lt;ul&gt;
  &lt;li&gt;Similarity and Similarity Measures&lt;/li&gt;
  &lt;li&gt;Chain Method of Clustering&lt;/li&gt;
  &lt;li&gt;Clustering Criterion Functions&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Iterative Optimization&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Clustering procedure – basic min. squared error&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;K-means Clustering&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Hierarchical Clustering&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;Mixture Densities: Gaussian Mixtures&lt;/li&gt;
  &lt;li&gt;Component Analysis: PCA, ICA&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;iterative-optimization&quot;&gt;Iterative Optimization&lt;/h2&gt;</content><author><name>KYG</name></author><category term="MLPR" /><summary type="html">Similarity and Similarity Measures Chain Method of Clustering Clustering Criterion Functions Iterative Optimization Clustering procedure – basic min. squared error K-means Clustering Hierarchical Clustering Mixture Densities: Gaussian Mixtures Component Analysis: PCA, ICA</summary></entry><entry><title type="html">[MLPR #] Unsupervised Classification 1 (fisher)</title><link href="https://shvtr159.github.io/mlpr/mlpr-unsupervised-classification-1/" rel="alternate" type="text/html" title="[MLPR #] Unsupervised Classification 1 (fisher)" /><published>2021-12-04T00:00:00+09:00</published><updated>2021-12-04T00:00:00+09:00</updated><id>https://shvtr159.github.io/mlpr/mlpr-unsupervised-classification-1</id><content type="html" xml:base="https://shvtr159.github.io/mlpr/mlpr-unsupervised-classification-1/">&lt;p&gt;Supervised 에서는 data에 label도 있고 전체 class의 갯수를 알 수 있기때문에 data로부터 그 분포를 추정할 수 있었다. unsupervised classification은 이러한 정보가 없을 때 data를 구분하는 방법이다. 
Unknown targets를 분류하는 방법에는 다양한 방법이 있는데 다음과 같은 방법이 있다.&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Criterion function 방법 : Sum of squared error, Min. variance, Scatter matrices, Optimization problem&lt;/li&gt;
  &lt;li&gt;Heuristic 방법 : Chain, Hierarchical, Min. spanning tree&lt;/li&gt;
  &lt;li&gt;Unmixing 방법 : Gaussian mixture, PCA, ICA&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;앞으로 다음 순서로 진행하며 unsupervised classification 방법에 대해 알아본다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Similarity and Similarity Measures&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Chain Method of Clustering&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Clustering Criterion Functions&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;Iterative Optimization&lt;/li&gt;
  &lt;li&gt;Clustering procedure – basic min. squared error&lt;/li&gt;
  &lt;li&gt;K-means Clustering&lt;/li&gt;
  &lt;li&gt;Hierarchical Clustering&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;여기까지는 Non-statistical한 방법이고, 이후 두 주제는 statistical한 방법이다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Mixture Densities: Gaussian Mixtures&lt;/li&gt;
  &lt;li&gt;Component Analysis: PCA, ICA&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;similarity-and-similarity-measures&quot;&gt;Similarity and Similarity Measures&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/79836443/146315768-90f03044-8073-4775-8140-9664492d7648.png&quot; alt=&quot;image&quot; width=&quot;40%&quot; height=&quot;40%&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;위 이미지는 2차 statistical(평균과 공분산)이 모두 같지만 smaple의 분포는 모두 다르다. 이를 분포의 혼합으로 만들어진다고 가정하면 근사화할 수 있겠지만 쉬운 작업은 아니다. 이러한 이유로 clustering을 사용하곤 한다. 그러나 clustering된 sample간의 유사성이나 분류를 평가하기 위해서는 측정 방법이 필요하다.&lt;/p&gt;

&lt;p&gt;클러스터링 결과를 Euclidean distance를 이용하여 측정하게 된다면 feature space에서의 translationis이나 rotation과 같은 변환에는 결과에 차이가 없지만, 일반적으로 scaling과 같은 선형 변환에 따라 결과가 변형되기 때문에 조심해야한다.&lt;/p&gt;

&lt;p&gt;다른 similarity  측정 방법&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Angular Similarity&lt;/strong&gt;&lt;br /&gt;
nonmetric similarity function으로 $S(x_i,x_j)=x_i^Tx_j/\left |x_i  \right |\left |x_j \right |$ (normalized 내적, $x_i$와 $x_j$사이 각의 코사인 값). 두 vector 사이의 각이 의미가 있을때 유용하다.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Binary Similarity&lt;/strong&gt;&lt;br /&gt;
$S(x_i,x_j)=x_i^Tx_i+x_j^Tx_j-x_i^Tx_j$로 계산된다. $x_i^Tx_j$는 공통으로 나타나는 feature의 개수로 결국 $S$는공통으로 나타내는 feature의 비율이다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;chain-method-of-clustering&quot;&gt;Chain Method of Clustering&lt;/h2&gt;
&lt;ol&gt;
  &lt;li&gt;첫번째 sample을 cluster #1 ($S_1$)으로 할당한다.&lt;/li&gt;
  &lt;li&gt;다음 sample과 지금 sample간의 거리 $d$를 계산하고  $d_0$(미리 정해둔 threshold)와 비교한다. 만약 $d&amp;lt;d_0$이면 sample을 같은 cluster로 분류하고, 반대의 경우 새로운 cluster를 생성한다.&lt;/li&gt;
  &lt;li&gt;다음 sample도 존재하는 모든 cluster와의 거리 $d$를 계산하고 최소값을 찾는다. 만약 $d_{min}&amp;lt;d_{0}$이면 해당 cluster로 분류하고 반대의 경우 이전과 같이 새로운 cluster를 생성한다.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;이때, $d$는 해당 cluster의 첫번째 sample과의 거리로 계산하거나 cluster의 sample mean과의 거리로 계산한다. 그러나 이 방법은 $d_0$와 sample의 차수에 sensitive하다는 문제점이 있다.&lt;/p&gt;

&lt;h2 id=&quot;clustering-criterion-functions&quot;&gt;Clustering Criterion Functions&lt;/h2&gt;
&lt;p&gt;Clustering을 수행하고 나면 clustering이 잘 되었는지 확인해야 한다. 그래서 criterion fucntion을 사용해 이 function을 최소화하거나 최대화하는 값을 찾아 좋은 clustering을 선택한다. 앞으로 사용할 표기를 먼저 정의한다.&lt;/p&gt;

&lt;p&gt;$J$개의 sample $x_1, …, x_j$의 집합 $z$를 $K$개의 subset $z_1, z_2, …, z_k$로 나눈다. 이 $K$개의 집합들의 $J$개의 sample들의 cluster quality를 평가한다.&lt;/p&gt;
&lt;h3 id=&quot;1-sum-of-squared-error-criterion&quot;&gt;1. Sum of Squared Error Criterion&lt;/h3&gt;
&lt;p&gt;가장 간단하면서도 널리 쓰이는 방법으로 cluster의 평균과 그 sample들간의 거리의 차의 제곱을 모두 합한다.&lt;/p&gt;

\[J_e=\sum^K_{i=1}{\sum_{x_j\in z_i}\left \| x_j-m_i \right \|^2}\]

&lt;p&gt;$m_i$는 $z_i$의 sample들의 평균. Sum square error는 $J_e$값이 최소가 될때 최소의 variance를 가지므로 이때 cloud가 compact하고 각각 잘 분리된 좋은 cluster라고 이야기 할 수 있다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/79836443/146320721-d69de763-7cc4-4a4f-97d9-7949a3bf2128.png&quot; alt=&quot;image&quot; width=&quot;40%&quot; height=&quot;40%&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;그러나 위 이미지와 같이 분포가 다른 경우 잘못된 clustering을 수행할 수도 있다.&lt;/p&gt;

&lt;h3 id=&quot;2-minimum-variance-criteria&quot;&gt;2. Minimum-Variance Criteria&lt;/h3&gt;
&lt;p&gt;이 방법은 cluster의 모든 sample들간의 평균 제곱 거리를 이용한다.&lt;/p&gt;

\[J_e=\frac{1}{2}\sum^K_{i=1}J_i\bar{s}_ i\]

\[\bar{s}_ i=\frac{1}{J_i^2}\sum_{x_j\in z_i}{\sum_{x_l\in z_i}\left \| x_j-x_l \right \|^2}\]

&lt;p&gt;$\bar{s}_ i$의 다른 방법으로는  $\left | x_j-x_l \right |^2$ 대신 $s(x_j,x_l)$($s$는 similarity function)을 사용하거나 전체 합 대신 최소값을 사용하여 $\bar{s}_ i=\min_{x_j,x_l\in z_i}[s(x_j,x_l)]$을 사용하는 방법도 있다.&lt;/p&gt;

&lt;h3 id=&quot;3-scattering-criteria&quot;&gt;3. Scattering Criteria&lt;/h3&gt;
&lt;p&gt;Scatter matrix로부터 sample의 scattering을 측정한다. 여기에 사용되는 mean vector와 scatter matrix에는 다음이 있다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/79836443/146324824-0ddcbd07-8698-4076-9c66-836647f71f62.png&quot; alt=&quot;image&quot; width=&quot;90%&quot; height=&quot;90%&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;전체 scatter matrix$S_T$는 within-cluster(클러스터 내) scatter matrix$S_W$와 Between-cluster(클러스터 간) scatter matrix$S_B$의 합으로 이루어진다. Scatter의 양에 관해 더 정확하게 하기위해 scatter matrix의 크기의 Scalar 측정을 필요로 한다. 이 측정에는 3가지 기준이 있다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Trace 기준&lt;/strong&gt;&lt;br /&gt;
대략적으로 trace는 좌표 방향들에서 분산들의 합의 비례하기 대문에 scattering 반경의 제곱을 측정한다.&lt;/li&gt;
&lt;/ul&gt;

\[Tr\{S_W\}=\sum^K_{i=1}{Tr\{S_i\}}=\sum^K_{i=1}\sum_{x_j\in z_i}{\left \| x_j-m_i \right \|^2}\]

\[Tr\{S_B\}=\sum^K_{i=1}J_i{\left \| m_i-m \right \|^2}\]

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Determinant 기준&lt;/strong&gt;&lt;br /&gt;
Determinant는 main axis들의 방향에서 분산들의 곱에 비례하므로, scattering volume의 제곱을 측정한다.&lt;/li&gt;
&lt;/ul&gt;

\[J_d=\left |S_W\right |=\sum^K_{i=1}{\left |S_i\right |}\]

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Invariant 기준 (불변적 기준)&lt;/strong&gt;&lt;br /&gt;
$\lambda_n$는 $S_W^{-1}S_B$의 n번째 eigenvalue이고 이는 lineartransformation에 불변하다.&lt;/li&gt;
&lt;/ul&gt;

\[J_f=Tr\{S_W^{-1}S_B\}=\sum^N_{n=1}{\lambda_n}\]

&lt;h2 id=&quot;fishers-linear-discriminent&quot;&gt;Fisher’s Linear Discriminent&lt;/h2&gt;</content><author><name>KYG</name></author><category term="MLPR" /><summary type="html">Supervised 에서는 data에 label도 있고 전체 class의 갯수를 알 수 있기때문에 data로부터 그 분포를 추정할 수 있었다. unsupervised classification은 이러한 정보가 없을 때 data를 구분하는 방법이다. Unknown targets를 분류하는 방법에는 다양한 방법이 있는데 다음과 같은 방법이 있다. Criterion function 방법 : Sum of squared error, Min. variance, Scatter matrices, Optimization problem Heuristic 방법 : Chain, Hierarchical, Min. spanning tree Unmixing 방법 : Gaussian mixture, PCA, ICA</summary></entry><entry><title type="html">[MLPR #] Nonparameteric Estimation 1 (미완)</title><link href="https://shvtr159.github.io/mlpr/mlpr-nonparametric-estimation/" rel="alternate" type="text/html" title="[MLPR #] Nonparameteric Estimation 1 (미완)" /><published>2021-12-03T00:00:00+09:00</published><updated>2021-12-03T00:00:00+09:00</updated><id>https://shvtr159.github.io/mlpr/mlpr-nonparametric-estimation</id><content type="html" xml:base="https://shvtr159.github.io/mlpr/mlpr-nonparametric-estimation/">&lt;p&gt;이전까지 확률을 이용해 density function을 추정했다면 Nonparameteric Technique는 math form 없이 density를 추정한다.&lt;/p&gt;

&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;

&lt;h2 id=&quot;estimation-procedure&quot;&gt;Estimation Procedure&lt;/h2&gt;
&lt;p&gt;$x$의 density를 추정하기 위한 절차를 알아보자&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;영역 $R_1, R_2, …$을 생성한다.&lt;/li&gt;
  &lt;li&gt;이때 영역 $R_j$는 j개의 sample들로 구성된다. ??&lt;/li&gt;
  &lt;li&gt;$R_j$의 크기를 $V_j$라고 한다&lt;/li&gt;
  &lt;li&gt;$R_j$에 속해있는 sample들의 개수를 $k_j$라고 한다&lt;/li&gt;
  &lt;li&gt;$p(x)$의 j번째 추정은 $p_j(x)=[k_j/j]/V_j$이다. $p_j(x)$는 다음과 같은 경우에 $p(x)$에 수렴한다.&lt;br /&gt;
 (1) $\lim_{j\to\infty}V_j=0$&lt;br /&gt;
 (2) $\lim_{j\to\infty}k_j=\infty$&lt;br /&gt;
 (3) $\lim_{j\to\infty}k_j/j=0$&lt;br /&gt;
위 조건을 만족하는 방법 두가지&lt;/li&gt;
  &lt;li&gt;영역의 크기를 축소시켜가는것. $V_j=1/\sqrt{j}$ (Parzen window)&lt;/li&gt;
  &lt;li&gt;$k_j=\sqrt{j}$로 설정하여 $x$ 주변 $k_j$개의 sample을 포함할때까지 크기를 증가시키는 것. (nearest neighbor)&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;two-popular-techniques&quot;&gt;Two Popular Techniques&lt;/h2&gt;
&lt;h3 id=&quot;1-parzen-window-estimation&quot;&gt;1) Parzen Window Estimation&lt;/h3&gt;
&lt;p&gt;window function은 $\Delta(\underline{u})=\Delta(\underline{x}-\underline{x}_ i)$로 정의한다($\underline{x}_ i$가 중심이 된다).&lt;/p&gt;

&lt;h3 id=&quot;2-k-nearest-neighbor&quot;&gt;2) K Nearest Neighbor&lt;/h3&gt;</content><author><name>KYG</name></author><category term="MLPR" /><summary type="html">이전까지 확률을 이용해 density function을 추정했다면 Nonparameteric Technique는 math form 없이 density를 추정한다.</summary></entry><entry><title type="html">[MLPR #] Parameter Estimation 2 (미완)</title><link href="https://shvtr159.github.io/mlpr/mlpr-parameter-estimation-2/" rel="alternate" type="text/html" title="[MLPR #] Parameter Estimation 2 (미완)" /><published>2021-12-02T00:00:00+09:00</published><updated>2021-12-02T00:00:00+09:00</updated><id>https://shvtr159.github.io/mlpr/mlpr-parameter-estimation%202</id><content type="html" xml:base="https://shvtr159.github.io/mlpr/mlpr-parameter-estimation-2/">&lt;p&gt;Parameter Estimation 1에서 추정 방법중 Maximum likelihood에 대해 알아보았다. 2에서는 나머지 한가지 방법인 Maximum a Posterior (MAP) estimation에 대해서 알아본다.
MLPR 11~13&lt;/p&gt;</content><author><name>KYG</name></author><category term="MLPR" /><summary type="html">Parameter Estimation 1에서 추정 방법중 Maximum likelihood에 대해 알아보았다. 2에서는 나머지 한가지 방법인 Maximum a Posterior (MAP) estimation에 대해서 알아본다. MLPR 11~13</summary></entry><entry><title type="html">[MLPR #] Parameter Estimation 1 (미완)</title><link href="https://shvtr159.github.io/mlpr/mlpr-parameter-estimation/" rel="alternate" type="text/html" title="[MLPR #] Parameter Estimation 1 (미완)" /><published>2021-12-01T00:00:00+09:00</published><updated>2021-12-01T00:00:00+09:00</updated><id>https://shvtr159.github.io/mlpr/mlpr-parameter-estimation</id><content type="html" xml:base="https://shvtr159.github.io/mlpr/mlpr-parameter-estimation/">&lt;p&gt;이전까지는 모든 statistics과 probability(prior probabiliteis, class-conditional densities(likelihood) 등)를 알 때 Bayes Classifier를 이용해 data가 어디에 속하는지 분류할 수 있었다. 그러나 이렇게 모든 statistics를 아는 상황은 드물기 때문에 data로부터 이를 추정해야만 한다. priori를 모른다고 가정할 때 다음 두 technique를 이용하여 $p(x\mid S_{i})$를 추정할 수 있다.&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Parametric&lt;/strong&gt; : $p(x\mid S_{i})$의 form을 알거나, 안다고 가정할 때 함수의 parameter를 추정한다. 예를 들어$p(x\mid S_{i})=N(x,m_i,\Sigma_i)$인 Gaussian 함수라고 할 때, training sample로부터 $m_i,\Sigma_i$를 추정하는 것이다. 이 방법에는 &lt;strong&gt;Maximum likelyhood estimation(최대 우도 추정)&lt;/strong&gt; 과 &lt;strong&gt;Maximum a Posterior (MAP) estimation(최대 사후 확률 추정)&lt;/strong&gt; (Bayesian estimation)이 있다.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Nonparametric&lt;/strong&gt; : density에 대한 정보도 없이 data만 있을때로 data로부터 density function을 추정한다.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;ML과 Bayesian의 주된 차이점은 ML는 paramter가 확실히 정해져 있지만 우리가 모르고 있다는 관점이고, bayesian은 parameter 자체를 random variable로 본다. bayesian learning은 parameter의 true value와 가까울수록 peak값에 가까워지므로 추가적인 sample이 들어오면 더 좋은 posteriori density로 update할 수 있다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/79836443/146154164-1aed9de4-b178-421d-849e-d147df19da1a.png&quot; alt=&quot;image&quot; width=&quot;40%&quot; height=&quot;40%&quot; /&gt;
&lt;img src=&quot;https://user-images.githubusercontent.com/79836443/146154305-28796a2e-df6c-429c-9c83-3ed53da102f3.png&quot; alt=&quot;image&quot; width=&quot;55%&quot; height=&quot;55%&quot; /&gt;&lt;center&gt;&lt;span style=&quot;color:rgb(150, 150, 150)&quot;&gt;Left: ML. true에 가까울수록 높다. / Right: MAP. sample이 많아질수록 peak에 가까워진다.&lt;/span&gt;&lt;/center&gt;&lt;/p&gt;
&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;해당 방법들에 대해 알아보기 전에 추정에 대해 간단히 알아본다.&lt;/p&gt;

&lt;p&gt;먼저 $\underline{\theta }$를 고정돼있지만 우리가 지금 모르는 parameter들의 vector라고 하자(ex. 평균 or 분산). 그리고 $\hat{\underline{\theta }}$은 $\underline{\theta }$의 추정값이라고 한다. $\underline{\theta }$는 결정되어있고, $\hat{\underline{\theta }}$는 random하다.&lt;/p&gt;

&lt;p&gt;또, $x_1, x_2, …$를 우리가 추정할 density로부터 추출한 random sample vector라고 한다. 각각의 $x_i$들은 iid(independent, identically, distributed)하다고 가정한다.&lt;/p&gt;

&lt;p&gt;이제 $\underline{z}=[x_1, x_2, … , x_J]$라 하면, $\hat{\underline{\theta }}=G(x_1, x_2, … , x_J)=G(\underline{z})=\hat{\underline{\theta }}(z)$으로 어떤한 process $G$를 수행하여 랜덤한 추정값을 얻게 되는 것이다.&lt;/p&gt;

&lt;h3 id=&quot;좋은-추정값의-특성&quot;&gt;좋은 추정값의 특성&lt;/h3&gt;
&lt;h4 id=&quot;1-unbiased-estimate&quot;&gt;1. Unbiased estimate&lt;/h4&gt;
&lt;p&gt;가장 중요한 성질. 기대값 $E(\hat{\theta})=\theta$이면 이를 unbiased estimate라고 한다. 표본 평균은 unbiased estimate이나 표본 분산은 biased estimate 이다.&lt;/p&gt;

&lt;h4 id=&quot;2-consistent-estimate&quot;&gt;2. Consistent estimate&lt;/h4&gt;
&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/79836443/146173297-87140ccb-0add-4190-b829-e5e1c7e5e974.png&quot; alt=&quot;image&quot; class=&quot;align-center&quot; /&gt;
표본의 크기가 커질수록 추정값이 실제 값 $\underline{\theta}$에 가까워지는 성질.&lt;/p&gt;

&lt;h4 id=&quot;3-efficient-estimate&quot;&gt;3. Efficient estimate&lt;/h4&gt;
&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/79836443/146173820-90aed70d-1f20-41f9-9bab-e8f935a54d68.png&quot; alt=&quot;image&quot; class=&quot;align-center&quot; /&gt;
추정값의 분산이 작게 나타나는 성질으로 추정값의 분산이 작을수록 더  efficient하다고 할 수 있다.&lt;sup&gt;&lt;a href=&quot;#footnote_1&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;

&lt;h4 id=&quot;4-sufficient-estimate&quot;&gt;4. Sufficient estimate&lt;/h4&gt;
&lt;p&gt;추정값이 $\underline{\theta}$에 대해 많은 정보를 포함하는지에 대한 성질.&lt;/p&gt;

&lt;h2 id=&quot;maximum-likelihood&quot;&gt;Maximum-Likelihood&lt;/h2&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;a name=&quot;footnote_1&quot;&gt;1&lt;/a&gt;: 이미지 출처 : 정보통신기술용어해설 http://www.ktword.co.kr/test/view/view.php?m_temp1=458&lt;br /&gt;&lt;/p&gt;</content><author><name>KYG</name></author><category term="MLPR" /><summary type="html">이전까지는 모든 statistics과 probability(prior probabiliteis, class-conditional densities(likelihood) 등)를 알 때 Bayes Classifier를 이용해 data가 어디에 속하는지 분류할 수 있었다. 그러나 이렇게 모든 statistics를 아는 상황은 드물기 때문에 data로부터 이를 추정해야만 한다. priori를 모른다고 가정할 때 다음 두 technique를 이용하여 $p(x\mid S_{i})$를 추정할 수 있다. Parametric : $p(x\mid S_{i})$의 form을 알거나, 안다고 가정할 때 함수의 parameter를 추정한다. 예를 들어$p(x\mid S_{i})=N(x,m_i,\Sigma_i)$인 Gaussian 함수라고 할 때, training sample로부터 $m_i,\Sigma_i$를 추정하는 것이다. 이 방법에는 Maximum likelyhood estimation(최대 우도 추정) 과 Maximum a Posterior (MAP) estimation(최대 사후 확률 추정) (Bayesian estimation)이 있다. Nonparametric : density에 대한 정보도 없이 data만 있을때로 data로부터 density function을 추정한다.</summary></entry><entry><title type="html">[MLPR #] Bayes Classifiers</title><link href="https://shvtr159.github.io/mlpr/mlpr-bayes-classifiers/" rel="alternate" type="text/html" title="[MLPR #] Bayes Classifiers" /><published>2021-10-26T00:00:00+09:00</published><updated>2021-10-26T00:00:00+09:00</updated><id>https://shvtr159.github.io/mlpr/mlpr-bayes-classifiers</id><content type="html" xml:base="https://shvtr159.github.io/mlpr/mlpr-bayes-classifiers/">&lt;p&gt;discriminant decision $g_i(\underline{x})$를 이용하여 모든 $i \neq j$에 대해 $g_i(\underline{x})&amp;gt;g_j(\underline{x})$ 분류를 사용한다. 이를 probability term으로 표현하면&lt;/p&gt;

\[g_i(\underline{x})=p(S_i \mid \underline{x})\]

\[\rightarrow \; g_i(\underline{x})=p(\underline{x} \mid S_i)P(S_i)\]

\[\rightarrow \; g_i(\underline{x})=\textup{ln}(p(\underline{x} \mid S_i))+\textup{ln}(P(S_i))\]

&lt;h2 id=&quot;normal-density&quot;&gt;Normal Density&lt;/h2&gt;</content><author><name>KYG</name></author><category term="MLPR" /><summary type="html">discriminant decision $g_i(\underline{x})$를 이용하여 모든 $i \neq j$에 대해 $g_i(\underline{x})&amp;gt;g_j(\underline{x})$ 분류를 사용한다. 이를 probability term으로 표현하면</summary></entry><entry><title type="html">[MLPR #] Bayes Decision Classification</title><link href="https://shvtr159.github.io/mlpr/mlpr-statistical-cassification1/" rel="alternate" type="text/html" title="[MLPR #] Bayes Decision Classification" /><published>2021-10-23T00:00:00+09:00</published><updated>2021-10-23T00:00:00+09:00</updated><id>https://shvtr159.github.io/mlpr/mlpr-statistical-cassification1</id><content type="html" xml:base="https://shvtr159.github.io/mlpr/mlpr-statistical-cassification1/">&lt;p&gt;Bayes Decision Theory : 이 방식은 모든 확률 값들을 알고 있다고 가정한다(평균, 분산 등).&lt;/p&gt;
&lt;h2 id=&quot;bayes-formula&quot;&gt;Bayes Formula&lt;/h2&gt;

\[P(S\mid x)=\frac{P(x\mid S)P(S_k)}{P(x)}\]

&lt;ul&gt;
  &lt;li&gt;$P(S\mid x)$ : posterior probability (사후 확률)&lt;/li&gt;
  &lt;li&gt;$P(x\mid S)$ : likelihood (우도, 가능도)&lt;/li&gt;
  &lt;li&gt;$P(S)$ : prior probability (사전 확률)&lt;/li&gt;
  &lt;li&gt;$P(x)$ : Evidence&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;bayes-decision-rule-for-최소-error-2-class&quot;&gt;Bayes Decision Rule for 최소 Error (2-class)&lt;/h2&gt;

\[\begin{matrix}
p(S_1\mid \underline{x})&amp;gt;p(S_2\mid \underline{x})\rightarrow \underline{x}\in S_1 \\ \\
p(S_1\mid \underline{x})&amp;lt;p(S_2\mid \underline{x})\rightarrow \underline{x}\in S_2
\end{matrix}\]

&lt;p&gt;즉, x는 두 class 중 확률이 더 높은 class에 속한다고 판단한다. 이를 Bayes Theorem을 이용하여 바꾸면&lt;/p&gt;

&lt;h3 id=&quot;decision-rule&quot;&gt;Decision Rule&lt;/h3&gt;

\[\begin{matrix}
p(\underline{x} \mid S_1)p(S_1)&amp;gt;p(\underline{x} \mid S_2)p(S_2) \rightarrow \underline{x}\in S_1 \\ \\
p(\underline{x} \mid S_1)p(S_1)&amp;lt;p(\underline{x} \mid S_2)p(S_2) \rightarrow \underline{x}\in S_2
\end{matrix}\]

&lt;p&gt;으로 표현되고 다음과 같이 다시 정리할 수 있다.&lt;/p&gt;

\[\frac{p(\underline{x} \mid S_1)}{p(\underline{x} \mid S_2)}\quad\begin{matrix}
\underline{x}\in S_1\\ 
&amp;gt;\\ 
&amp;lt;\\ 
\underline{x}\in S_2
\end{matrix}\quad \frac{P(S_1)}{P(S_2)}\]

&lt;p&gt;이 때, $l(x) = \frac{p(\underline{x} \mid S_1)}{p(\underline{x} \mid S_2)}$를 likelihood ratio(우도 비), $\frac{P(S_1)}{P(S_2)} = T$를 threshold value 라고 한다.&lt;/p&gt;

&lt;p&gt;위 정리된 식은 Log를 취해 *를 +로 바꿔 cost를 크게 줄일 수 있고, 다음과 같이 변경된다.&lt;/p&gt;

\[h(\underline{x})=-\textup{ln}(l(\underline{x}))=\textup{ln}(p(\underline{x} \mid S_2))-\textup{ln}(p(\underline{x} \mid S_1))&amp;lt;\textup{ln}(\frac{P(S_1)}{P(S_2)})\quad \Rightarrow \; \underline{x}\in S_1\]

&lt;h3 id=&quot;probability-of-error&quot;&gt;Probability of Error&lt;/h3&gt;
&lt;p&gt;이는 error region을 integrate 하는 형식으로 구해진다. 2 class의 경우&lt;/p&gt;

\[P_e=p(S_1)\int_{\Gamma_2}p(\underline{x} \mid S_1)dx+p(S_2)\int_{\Gamma_1}p(\underline{x} \mid S_2)dx\]

&lt;p&gt;이며 다중 class의 경우 $P_e=1-P(correct)$ 으로 알기 쉽게 표현할 수 있다. 이때, $P(correct)$ 은 $\sum_{i=1}^{K}\int_{\Gamma_i}p(\underline{x} \mid S_i)P(S_i)d\underline{x}$ 이다.&lt;/p&gt;
&lt;h2 id=&quot;bayes-decision-rule-for-최소-risk-2-class&quot;&gt;Bayes Decision Rule for 최소 Risk (2-class)&lt;/h2&gt;
&lt;p&gt;Bayes minimun error를 일반화 한다. $C(S_k \mid S_j)$를 $\underline{x}$가 $S_j$인데 $S_k$로 판별했을 때의 cost라고 하자. 그리고 이는 간단히 $C_{kj}=C(S_k \mid S_j)$로 표기한다(책에서는 $C_{kj}$ 대신 $\lambda_{kj}$로 표현하였다). 일반적으로 틀렸을 때 초래되는 손실은 맞을 때보다 더 크므로 $C_{21}&amp;gt;C_{11}$, $C_{12}&amp;gt;C_{22}$이다. 이를 한번에 matrix로 다음과 같이 표기한다.&lt;/p&gt;

\[\underline{C}=\begin{bmatrix}
C_{11} &amp;amp; C_{12}\\ 
C_{21} &amp;amp; C_{22}
\end{bmatrix}\]

&lt;p&gt;이때, 조건부 평균 risk (conditional avarage loss or risk) $R(S_k \mid \underline{x})$이고 2 class 에서 이 식은 모든 class의 값을 합한&lt;/p&gt;

\[\begin{matrix}
R(S_1 \mid \underline{x})=C(S_1 \mid S_1)P(S_1 \mid \underline{x})+C(S_1 \mid S_2)P(S_2 \mid \underline{x})\\ 
R(S_2 \mid \underline{x})=C(S_2 \mid S_1)P(S_1 \mid \underline{x})+C(S_2 \mid S_2)P(S_2 \mid \underline{x})
\end{matrix}\]

&lt;p&gt;이며, Decision cule은 total expected risk를 최소화 하기위한 action으로 다음과 같다.&lt;/p&gt;

\[R=\int_{\Gamma_1}R(S_1 \mid \underline{x})p(x)d\underline{x}+\int_{\Gamma_2}R(S_2 \mid \underline{x})p(x)d\underline{x}\]

&lt;p&gt;여기서 R을 최소화하기 위해 각 $\underline{x}$에 대한 $R(S_k \mid \underline{x})$이 최소화되는 영역으로 선택한다(Risk는 작을수록 좋으므로).&lt;/p&gt;

\[\begin{matrix}
R(S_1 \mid \underline{x}) &amp;lt; R(S_2 \mid \underline{x}) \rightarrow S_1 \\ 
R(S_1 \mid \underline{x}) &amp;gt; R(S_2 \mid \underline{x}) \rightarrow S_2 
\end{matrix}\]

&lt;h3 id=&quot;decision-rule-minimum-risk-classifier&quot;&gt;Decision Rule (Minimum Risk Classifier)&lt;/h3&gt;

\[R(S_1 \mid \underline{x}) \; \begin{matrix}
S_1\\ 
&amp;lt;\\ 
&amp;gt;\\ 
S_2
\end{matrix}\; R(S_2 \mid \underline{x})\]

&lt;p&gt;이를 다시 이전의 $C$를 이용한 식으로 바꾸면&lt;/p&gt;

\[C_{11}P(S_1 \mid \underline{x})+C_{12}P(S_2 \mid \underline{x}) \quad \begin{matrix}
&amp;lt;\\ 
&amp;gt;
\end{matrix}\; C_{21}P(S_1 \mid \underline{x})+C_{22}P(S_2 \mid \underline{x})\]

&lt;p&gt;이고, 같은 $P$끼리 정리하여 묶어낸 뒤 $P(S_k\mid x)=\frac{P(S_k)P(x\mid S_k)}{P(x)}$ 로 바꿔 쓴 뒤, likelihood ratio가 나타나도록 정리하면 최종적으로 다음 식이 된다.&lt;/p&gt;

\[l(\underline{x})=\frac{p(\underline{x} \mid S_1)}{p(\underline{x} \mid S_2)}\quad \begin{matrix}
&amp;gt;\\ 
&amp;lt;\\ 
\end{matrix}\quad \frac{(C_{12}-C_{22})P(S_2)}{(C_{21}-C_{11})P(S_1)}\]

&lt;p&gt;이때, 만약 $C_{11}=0, C_{12}=1, C_{21}=1,C_{22}=0$ 이면 다음과 같은 형태의 &lt;strong&gt;Bayes minimum error rule&lt;/strong&gt;이 된다.&lt;/p&gt;

\[l(\underline{x})=\frac{p(\underline{x} \mid S_1)}{p(\underline{x} \mid S_2)}\; \begin{matrix}
&amp;gt;\\ 
&amp;lt;\\ 
\end{matrix}\; \frac{P(S_2)}{P(S_1)}\]

&lt;h2 id=&quot;bayes-minimum-error-and-minimum-risk-다중-class&quot;&gt;Bayes Minimum Error and Minimum Risk (다중 class)&lt;/h2&gt;
&lt;h3 id=&quot;bayes-minimum-error--multiple-classes&quot;&gt;Bayes Minimum Error – Multiple Classes&lt;/h3&gt;
&lt;p&gt;모든 $i \neq j$에 대해 $P(S_i \mid \underline{x} )&amp;gt;P(S_j \mid \underline{x})$ 이면 $\underline{x}\in S_i$ 이다. 다시 변경하면, 모든 $i \neq j$에 대해 $p(\underline{x} \mid S_i)p(S_i)&amp;gt;p(\underline{x} \mid S_j)p(S_j)$ 이면 $\underline{x}\in S_i$ 이다. Discriminant function은 다음과 같다.&lt;/p&gt;

\[g_i(\underline{x})=p(\underline{x} \mid S_i)p(S_i)\]

&lt;h3 id=&quot;bayes-minimum-risk--multiple-classes&quot;&gt;Bayes Minimum Risk – Multiple Classes&lt;/h3&gt;
&lt;p&gt;$R(S_k \mid \underline{x})=\sum_{i=1}^{K}C_{ki}P(S_i\mid \underline{x})$를 conditional loss로 변경하면 $R(S_k \mid \underline{x})=\sum_{i=1}^{K}C_{ki}P(\underline{x} \mid S_i)P(S_i)$ 이다. 만약, 모든 $i \neq j$에 대해 $R_c(S_i \mid \underline{x})&amp;lt;R_c(S_j \mid \underline{x})$ 이면 $\underline{x}\in S_i$ 이다. Discriminant function은 다음과 같다.&lt;/p&gt;

\[g_k(\underline{x})=-R_c(S_k \mid \underline{x})\]

&lt;p&gt;’$-$’를 곱해주는 이유는 위의 표현처럼 $g_i(\underline{x})&amp;gt;g_j(\underline{x})$ 를 유지하기 위해서 이다.&lt;/p&gt;

&lt;p&gt;$R_c$ 식은 다음과 같이 행렬식의 곱 형태로 나타낼 수 있고 이 경우 2가지 special case를 확인하기에 편리하다.&lt;/p&gt;

\[R_c(S_k \mid \underline{x})=\begin{bmatrix}
C_{11} &amp;amp; C_{12} &amp;amp; \cdots\\ 
C_{21}&amp;amp; \ddots  &amp;amp; \\ 
\cdots  &amp;amp;  &amp;amp; C_{kk}
\end{bmatrix}\begin{bmatrix}
p(\underline{x} \mid S_1)P(S_1)\\ 
p(\underline{x} \mid S_2)P(S_2)\\ 
\cdots
\end{bmatrix}\]

&lt;ol&gt;
  &lt;li&gt;special case 1 : Symmetric 0-1 cost function&lt;/li&gt;
  &lt;li&gt;special case 2 : Diagonal Cost Function&lt;/li&gt;
&lt;/ol&gt;</content><author><name>KYG</name></author><category term="MLPR" /><summary type="html">Bayes Decision Theory : 이 방식은 모든 확률 값들을 알고 있다고 가정한다(평균, 분산 등). Bayes Formula</summary></entry><entry><title type="html">[MLPR #1] Introduction</title><link href="https://shvtr159.github.io/mlpr/mlpr-1-notation/" rel="alternate" type="text/html" title="[MLPR #1] Introduction" /><published>2021-10-20T00:00:00+09:00</published><updated>2021-10-20T00:00:00+09:00</updated><id>https://shvtr159.github.io/mlpr/mlpr-1-notation</id><content type="html" xml:base="https://shvtr159.github.io/mlpr/mlpr-1-notation/">&lt;h2 id=&quot;notation&quot;&gt;Notation&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;$\underline{ \textbf{x}}$ : data 벡터&lt;/li&gt;
  &lt;li&gt;prototypes:
    &lt;ul&gt;
      &lt;li&gt;$\underline{y}_ m^{(k)}$ : class $S_ {k}$에 속한 m번째 prototype&lt;/li&gt;
      &lt;li&gt;k = class index&lt;/li&gt;
      &lt;li&gt;$m_k$ = $S_ {k}$에 있는 prototype들의 번호&lt;/li&gt;
      &lt;li&gt;$\underline{y}_ m^{(k)}$, m = 1,2, … , $m_k$ 는  class $S_ {k}$의 모든 prototype로 정의&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;classification&quot;&gt;Classification&lt;/h2&gt;
&lt;p&gt;각각의 Class를 나누기 위해서는 Decision Rule이 결정되어야 한다. 예를 들어 변수 값에 따라 분류 할 때, 값이 5.5 초과면 $S_ {1}$, 이하면 $S_ {2}$로 분류할 수 있다. 그러나 이러한 feature가 1개일때보다는 2개일때 더 정확한 분류를 할 수 있고, 더 많아질수록 더 정확히 분류할 수 있다. 이렇게 fature의 차원이 커짐에 따라 decision surface의 차원도 점, 선, 면 으로 점점 증가하게 된다.&lt;/p&gt;

&lt;p&gt;이렇게 나눠진 많은 Class들 중 $\underline{ \textbf{x}}$ 가 어디에 속하는 지 알기 위해서는 해당 class와 $\underline{ \textbf{x}}$의 거리를 측정해야 한다.&lt;/p&gt;</content><author><name>KYG</name></author><category term="MLPR" /><summary type="html">Notation $\underline{ \textbf{x}}$ : data 벡터 prototypes: $\underline{y}_ m^{(k)}$ : class $S_ {k}$에 속한 m번째 prototype k = class index $m_k$ = $S_ {k}$에 있는 prototype들의 번호 $\underline{y}_ m^{(k)}$, m = 1,2, … , $m_k$ 는 class $S_ {k}$의 모든 prototype로 정의</summary></entry><entry><title type="html">PointNet++: Deep Hierarchical Feature Learning on Point Sets in a Metric Space</title><link href="https://shvtr159.github.io/%EB%85%BC%EB%AC%B8/pointnet-deep-hierarchical-feature-learning-on-point-sets-in-a-metric-space/" rel="alternate" type="text/html" title="PointNet++: Deep Hierarchical Feature Learning on Point Sets in a Metric Space" /><published>2021-09-27T00:00:00+09:00</published><updated>2021-09-27T00:00:00+09:00</updated><id>https://shvtr159.github.io/%EB%85%BC%EB%AC%B8/pointnet-deep-hierarchical-feature-learning-on-point-sets-in-a-metric-space</id><content type="html" xml:base="https://shvtr159.github.io/%EB%85%BC%EB%AC%B8/pointnet-deep-hierarchical-feature-learning-on-point-sets-in-a-metric-space/">&lt;p&gt;PointNet++은 PointNet이 point가 존재하는 metric space에 의해 유도된 local structure를 활용하지 못해서 fine-grained&lt;sup&gt;&lt;a href=&quot;#footnote_1&quot;&gt;1&lt;/a&gt;&lt;/sup&gt; 패턴들을 잘 인식하지 못하고 복잡한 scene들을 일반화하는 능력이 떨어지는 문제를 해결하기 위해 제안되었다. PointNet++은 입력 point set의 nested partitioning에 PointNet을 recursive하게 적용하는 hierarchical 신경망이다. 이 네트워크는 metric space distance를 활용하여 contextual scale이 증가하는 local feature를 학습할 수 있다.&lt;/p&gt;

&lt;h2 id=&quot;1-introduction&quot;&gt;1. Introduction&lt;/h2&gt;
&lt;p&gt;기존 PointNet의 아이디어는 각 point의 공간 encoding을 학습하고, 모든 개별 point feature들을 global 포인트 클라우드 signature와 aggregate하는 것이었다. 그러나 이런 구조는 metric에 의해 유도된 local structure를 활용하지 않는다. 그러나 convolutional architecture의 성공에 local structure를 활용하는 것이 중요한 요소라는 것이 증명되어왔다. CNN은 multi-resolution hierarchy를 따라 점점 더 큰 scale의 feature를 찾아낼 수 있다. CNN 구조 특성상 낮은 level의 layer에서는 작은 receptive field를 가지고 높은 layer에서는 큰 receptive field를 가지기 때문이다. 이러한 hierarchy를 따라 local pattern들을 추상화하는 기능은 일반화에 더욱더 유용하다.&lt;/p&gt;

&lt;p&gt;해서, PointNet++이라는 hierarchical 신경망을 소개한다. 먼저, point set을 distance metric에 따라 겹치는 local 영역으로 분할한다. 이를 통해 위에서 이야기한 CNN과 마찬가지로 작은 neighborhood에서 작은 geometric structure를 고려하는 local feature를 추출한다. 이 local feature는 더 큰 unit으로 그룹화되고, 더 높은 level의 feature가 생성되도록 한다. 이 작업을 전체 point set의 feature를 얻을 때까지 반복한다.&lt;/p&gt;

&lt;p&gt;PointNet++은 다음 두 가지 문제를 해결할 수 있어야 한다.&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;point set의 분할을 생성하는 방법&lt;/li&gt;
  &lt;li&gt;local feature learner를 통해 point set이나 local featrue를 추상화하는 방법&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;이 두 문제는 서로 연관되어있는데 그 이유는 pointset의 분할은 여러 partition들에 걸쳐 공통적인 구조를 만들어 내야 하기 때문이다. 따라서, convolution 설정에서와 같이 local feature learner들은 weight를 공유할 수 있다. 이 local feature learner로 PointNet을 사용한다. PointNet은 basic building block으로서, local points나 features를 더 높은 level의 표현으로 추상화한다. 이러한 관점에서, PontNet++은 input set의 nested partitioning에 PointNet을 recursive하게 적용한다고 할 수 있다.&lt;/p&gt;

&lt;p&gt;point set의 overlapping partitioning 방법도 주된 문제이다. 일단, 각 partition은 Euclidean space에서 중심 위치와 scale을 parameter로 가지는 neighborhood ball로 정의한다. 또, 모든 set을 균일하게 다루기 위해 farthest point smapling (FPS)&lt;sup&gt;&lt;a href=&quot;#footnote_2&quot;&gt;2&lt;/a&gt;&lt;/sup&gt; 알고리즘을 이용해 중심점을 선택한다.&lt;/p&gt;

&lt;p&gt;PointNet++의 주된 contribution은 다음과 같다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;여러 scale에서 neighborhoods를 활용해 robustnessd와 detail capture를 달성하였다.&lt;/li&gt;
  &lt;li&gt;학습시키는 동안 random input dropout을 이용해 network가 찾아진 pattern들에 대해 adaptive하게 weight를 적용하고, input data에 따라 multi-scale feature들을 결합하는 방법을 학습하도록 하였다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;2-problem-statement&quot;&gt;2. Problem Statement&lt;/h2&gt;
&lt;p&gt;$\mathcal{X}=(M,d)$ 가 Euclidean space $\mathbb R^n$에서 상속된 discrete metric space라고 가정한다. 이때, $M\subseteq \mathbb R^n$ 은 point set이고, $d$는 distance metric이다. 또, Euclidean space $M$는 밀도가 균일하지 않은 부분도 있다. 이러한 $\mathcal{X}$를 입력으로 받고 $\mathcal{X}$에 대한 semantic interest의 정보를 생성하는 set function $f$를 생성하도록 학습시킨다. 이 $f$는 $\mathcal{X}$에 label을 할당하는 classification 함수나 $M$의 각 멤버에 point 별 label을 할당하는 segmentation 함수가 될 수 있다.&lt;/p&gt;

&lt;h2 id=&quot;3-method&quot;&gt;3. Method&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/79836443/135207876-43abf960-6fd9-4205-9eb1-e45c67ad0028.png&quot; alt=&quot;image&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;
&lt;center&gt;&lt;span style=&quot;color:rgb(150, 150, 150)&quot;&gt;hierarchical feature learning 구조&lt;/span&gt;&lt;/center&gt;

&lt;h3 id=&quot;32-hierarchical-point-set-feature-learning&quot;&gt;3.2 Hierarchical Point Set Feature Learning&lt;/h3&gt;
&lt;p&gt;PointNet++의 hierarchical 구조는 여러 개의 &lt;em&gt;set abstraction&lt;/em&gt; level로 구성된다. 각 level에서는 points set이 처리되고 추상화되어 더 적은 수의 element를 가지는 새로운 set이 생성된다. set abstraction level은 다음 3가지 key layer로 구성되며, 자세한 설명은 뒤에 다시 한다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;em&gt;Sampling layer&lt;/em&gt; : local region의 centroid를 찾는다.&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;Grouping layer&lt;/em&gt; : centroid 주위의 “neighboring” point들을 찾아 local region sets를 구성한다.&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;PoinNet layer&lt;/em&gt; : mini-PointNet을 사용해서 local region pattern들을 feature vector로 encoding 한다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;set abstraction level은  input으로 $N\times (d+C)$ ($N$ : point 개수, $d$ : coordinates dimension, $C$ : point feature dimension) matrix를 받고  output으로 $N’\times (d+C’)$ ($N’$ : subsampling된 point 개수, $C’$ : local context를 요약한 feature vector dimensioin)  matrix를 출력한다.&lt;/p&gt;

&lt;h4 id=&quot;sampling-layer&quot;&gt;Sampling layer&lt;/h4&gt;
&lt;p&gt;input points $\lbrace x_{1}, x_{2}, …, x_{n} \rbrace$가 주어질 때, iterative farthest poin sampling (FPS)을 사용하여 input의 부분집합 $\lbrace x_{i_{1}}, x_{i_{2}}, …, x_{i_{m}} \rbrace$를 생성한다. FPS는 이전까지 sampling된 point들에서 가장 먼 point를 선택하는 방법으로 $x_{i_{j}}$는 $\lbrace x_{i_{1}}, x_{i_{2}}, …, x_{i_{j-1}} \rbrace$의 point들, 즉 이전까지 sampling된 point들에서 가장 먼 point이다. 이 방법은 random sampling과 비교했을 때 더 우수한 결과를 얻을 수 있었다. 데이터 분포가 균일하지 않기 때문에 이러한 방식으로 데이터에 의존하여 receptive field를 생성한다.&lt;/p&gt;

&lt;h4 id=&quot;grouping-layer&quot;&gt;Grouping layer&lt;/h4&gt;
&lt;p&gt;Grouping layer는 $N\times (d+C)$ 크기의 point set과 $N’\times d$ 크기의 centriods set를 input으로 받아 grouping을 수행한다. output은 $N’\times K\times (d+C)$ 의 point set 그룹들이다. 이 각 그룹은 local region이고, $K$는 centriod points의 neighborhood point 개수(local region에 속하는 point 개수)이다. 여기서는 ball query를 이용해 $K$가 그룹에 따라 다르지만, 다음의 PointNet layer가 point의 수를 flexible하게 고정된 길이의 local region feature vector로 변환해준다.&lt;/p&gt;

&lt;p&gt;ball query는 query point에서 radius 내에 있는 모든 point를 찾는다. 이 방법은 고정된 개수의 주위 point를 찾는 $K$ nearest neighbor (kNN)과 비교했을 때, 영역의 크기가 고정되어있기 때문에 공간 전반에 걸쳐 local region feature가 더 일반화될 수 있다.&lt;/p&gt;

&lt;h4 id=&quot;pointnet-layer&quot;&gt;PointNet layer&lt;/h4&gt;
&lt;p&gt;input은Grouping layer에서 나온 $N’\times K\times (d+C)$의 크기를 가지는 $N’$개의 local region이다. output의 각 local region은 그 영역의 centriod와 centroid의 주변을 encoding 하는 local feature에 의해 추상화된다. 그 크기는 $N’\times (d+C’)$이다.&lt;/p&gt;

&lt;p&gt;local 영역에서 point의 좌표는 $x_i^{(j)} = x_i^{(j)} - \hat{x}^{(j)}$ ($i=1, …, K, j=1, …, d, \hat{x}$ : centroid의 좌표)을 이용해  centriod과의 상대적인 좌표로 바꿔 사용한다. 이 상대적인 좌표를 이용해 local 영역에 있는 point간의 위치적 관계를 담을 수 있다.&lt;/p&gt;

&lt;h3 id=&quot;33-robust-feature-learning-under-non-uniform-sampling-density&quot;&gt;3.3 Robust Feature Learning under Non-Uniform Sampling Density&lt;/h3&gt;
&lt;p&gt;Point set은 대부분 일정하지 않은 밀도로 분포되어 있다. density한 밀도 분포를 가진 point cloud로 학습된 네트워크는 sparse한 point cloud로 generalize 하기 어렵고 그 반대도 마찬가지이다. 때문에 dense하게 얻어진 영역에서 확대하며 작은 디테일을 확인하고 싶지만, sparse한 영역에서 이를 수행하면 제대로 된 local pattern을 얻을 수 없다. 이러한 경우 더 큰 scale에서 pattern을 확인해야 하는데 이를 위해 input sampling density가 달라질 때, 서로 다른 scale의 영역에서 얻어진 featture를 결합하는 방법을 학습하는 density adaptive PointNet layer를 제안하였다. 이 PointNet layer를 이용한 hierarchical network를 PointNet++이라고 이름 지었다.&lt;/p&gt;

&lt;p&gt;3.2절에서 각각의 abstraction level은 하나의 scale에서 feature extraction과 grouping을 수행하였다. PointNet++은 각 abstraction level은 다양한 scale의 local pattern을 추출하고 이를 local point 밀도에 따라 지능적으로 결합한다. local 영역을 그룹화하고 서로 다른 scale에서 얻어진 feature를 결합하기 위해 다음 2가지의 density adaptive layer를 제안하였다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/79836443/135259615-d7e6b0f9-8f02-4970-8752-735d3149a691.png&quot; alt=&quot;image&quot; class=&quot;align-center&quot; width=&quot;70%&quot; height=&quot;70%&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;multi-scale-grouping-msg&quot;&gt;Multi-scale grouping (MSG)&lt;/h4&gt;
&lt;p&gt;그림에서 보이는 것처럼 가장 간단하면서도 효과적으로 다양한 scale의 pattern을 찾아내는 방법은 다른 scale의 grouping layer를 적용한 뒤 PointNet을 이용해 각각 다른 scale에서 feature를 추출하는 것이다. 이 다른 scale에서 추출한 feature들을 concatenate하여 multi-scale feature를 생성한다.&lt;/p&gt;

&lt;p&gt;저자는 network를 훈련시키기 위해 &lt;em&gt;random input dropout&lt;/em&gt;을 수행했다. &lt;em&gt;random input dropout&lt;/em&gt;이란 각 instance를 랜덤한 확률로 input point들 중 일부를 랜덤하게 dropping out 하는 것으로 random하게 downsampling을 수행한다고 생각할 수 있다. 이 방법을 이용해 다양한 sparsity와 uniformity를 가지는 training set으로 네트워크를 훈련시킬 수 있다.&lt;/p&gt;

&lt;h4 id=&quot;multi-resolution-grouping-mrg&quot;&gt;Multi-resolution grouping (MRG)&lt;/h4&gt;
&lt;p&gt;위에서 설명한 MSG는 모든 centroid point에 대해 넓은 scale neighborhoods에서 local PointNet을 실행하기 때문에 계산 비용이 많이 든다. 특히 가장 낮은 level에서는 centroid point의 수가 매우 많기 때문에 time cost가 매우 중요하다.&lt;/p&gt;

&lt;p&gt;이러한 이유로 MRG라는 새로운 대안을 제시한다. MRG 이미지에서 level $L_i$의 영역에서의 두 vector를 concatenation하여 feature vector를 만든다. 한 vector(왼쪽 vector)는 한 단계 낮은 level $L_{i-1}$에서 set abstraction level을 이용하여 각 subregion의 feature를 요약해서 얻는다. 다른 한 vector(오른쪽)는 local 영역의 모든 raw point들을 단일 PointNet을 사용하여 직접 처리하여 얻은 feature이다.&lt;/p&gt;

&lt;p&gt;만약 local 영역의 density가 낮다면, 첫 번째 vector를 계산하는 subregion은 더 spaerse한 point들을 포함하고 sampling 부족 문제를 더 많이 겪기 때문에 첫 번째 vector의 신뢰도가 두 번째 vector에 비해 더 떨어진다. 반대로 local 영역의 density가 높다면, 첫 번째 vector가  더 낮은 level에서 높은 해상도로 recursive하게 검사할 수 있는 능력이 있기 때문에 더 작고 디테일한 정보를 제공해줄 수 있다.&lt;/p&gt;

&lt;p&gt;MSG와 비교했을 때, 이 방법이 더 효율적이다.&lt;/p&gt;

&lt;h3 id=&quot;34-point-feature-propagation-for-set-segmentation&quot;&gt;3.4 Point Feature Propagation for Set Segmentation&lt;/h3&gt;
&lt;p&gt;set abstraction layer에서 기존의 point set은 subsampling 된다. 그러나 semantic point labeling과 같은 segmentation task에서 기존에 있던 모든 point에 대한 point feature를 얻어야 한다.&lt;/p&gt;

&lt;p&gt;이를 위해 거리 기반 interpolation과 level을 통과하는 skip link를 사용하는 계층적 전파(hierarchical propagation) 전략을 사용한다. &lt;em&gt;feature propagation&lt;/em&gt; level에서, $N_l \times (d+C)$ point에서 $N_{l-1}$로 point feature를 propagation 한다($N_l, N_{i-1}$은 set abstraction level $l$에서의 input과 output point set 크기이며 $N_l\leq N_{i-1}$이다).&lt;/p&gt;

&lt;p&gt;interpolation : $N_{l-1}$ 개의 point의 좌표에서 $N_l$ point들의 feature value $f$를 interpolation하여 feature propagation을 수행한다. interpolation 방법으로는 $k$ nearest neighbors 방법 기반의 inverse distance weighted average를 사용한다(문단 이후 수식). $N_{l-1}$ point들에서 얻어진 interpolated feature들은 set abstraction level에서 온 skip linked point feature들과 concatenate된다. 이후 concatenate된 feature들은 “unit pointnet”을 통과하는데, 이는 CNN에서 $1 \times 1$ 컨볼루션과 유사하다. 이 과정은 기존 point set에 feature를 전파할 때까지 반복된다.&lt;/p&gt;

\[f^{(j)}(x)=\frac{\sum_{i=1}^{k}w_{i}(x)f_{i}^{(j)}}{\sum_{i=1}^{k}w_{i}(x)}\quad \textup{where}\quad w_{i}(x)=\frac{1}{d(x,x_{i})^p},\;j=1, ...,C\]

&lt;p&gt;&lt;br /&gt;
&lt;br /&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;a name=&quot;footnote_1&quot;&gt;1&lt;/a&gt;: 세분화된 것을 의미하는 말로 여기서는 작은 패턴들을 의미한다. 반대말로 coarse-grained가 있다.&lt;br /&gt;
&lt;a name=&quot;footnote_2&quot;&gt;2&lt;/a&gt;: 서로 간의 거리가 가장 먼 점들을 선택하는 과정&lt;/p&gt;</content><author><name>KYG</name></author><category term="논문" /><summary type="html">PointNet++은 PointNet이 point가 존재하는 metric space에 의해 유도된 local structure를 활용하지 못해서 fine-grained1 패턴들을 잘 인식하지 못하고 복잡한 scene들을 일반화하는 능력이 떨어지는 문제를 해결하기 위해 제안되었다. PointNet++은 입력 point set의 nested partitioning에 PointNet을 recursive하게 적용하는 hierarchical 신경망이다. 이 네트워크는 metric space distance를 활용하여 contextual scale이 증가하는 local feature를 학습할 수 있다.</summary></entry><entry><title type="html">머신러닝 시스템의 종류</title><link href="https://shvtr159.github.io/ml/ml/" rel="alternate" type="text/html" title="머신러닝 시스템의 종류" /><published>2021-09-14T00:00:00+09:00</published><updated>2021-09-14T00:00:00+09:00</updated><id>https://shvtr159.github.io/ml/ml</id><content type="html" xml:base="https://shvtr159.github.io/ml/ml/">&lt;p&gt;핸즈온 머신러닝의 머신러닝 내용 일부를 정리.&lt;/p&gt;
&lt;h2 id=&quot;머신러닝-시스템의-종류&quot;&gt;머신러닝 시스템의 종류&lt;/h2&gt;
&lt;p&gt;머신러닝 시스템은 다음과 같이 분류할 수 있지만 서로 배타적이지 않고 원하는 대로 연결 가능하다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;훈련 지도 여부 : 지도 학습, 비지도 학습, 준지도 학습, 강화 학습&lt;/li&gt;
  &lt;li&gt;실시간 훈련 여부 : 온라인 학습, 배치 학습&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;훈련-지도-여부&quot;&gt;훈련 지도 여부&lt;/h3&gt;
&lt;h4 id=&quot;지도-학습-supervised-learning&quot;&gt;지도 학습 (supervised learning)&lt;/h4&gt;
&lt;p&gt;지도학습에는 훈련 데이터에 label(혹은 target이란 표현도 사용됨) 이라는 답이 포함된다. 지도학습에는 분류(classification), 회귀(regression)이 해당된다. 일부 회귀 알고리즘은 분류에 사용할 수도 있고, 반대의 경우도 있다. 그 예로 로지스틱 회귀는 class에 속할 확률을 출력한다.&lt;/p&gt;

&lt;p&gt;중요한 지도 학습 알고리즘들&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;k-최근접 이웃 (K-Nearest Neightbors)&lt;/li&gt;
  &lt;li&gt;선형 회귀 (Linear Regression)&lt;/li&gt;
  &lt;li&gt;로지스틱 회귀 (Logistic Regrassion)&lt;/li&gt;
  &lt;li&gt;서포트 벡터 머신(Supprot Vector Machines, SVM)&lt;/li&gt;
  &lt;li&gt;결정 트리(Decision Tree)와 랜덤 포레스트(Random Forests)&lt;/li&gt;
  &lt;li&gt;신경망 (Neural networks)&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;비지도-학습-unsupervised-learning&quot;&gt;비지도 학습 (unsupervised learning)&lt;/h4&gt;
&lt;p&gt;lable 없는 훈련 데이터를 이용해 시스템 스스로 학습.&lt;/p&gt;

&lt;p&gt;대표적 비지도 학습&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;군집 (clustering)&lt;/li&gt;
  &lt;li&gt;시각화 (visualization)와 차원 축소 (dimensionality reduction)&lt;/li&gt;
  &lt;li&gt;이상치 탐지 (anomaly detection)&lt;/li&gt;
  &lt;li&gt;연관 규칙 학습 (Association rule learning)&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;준지도-학습-semisupervised-learning&quot;&gt;준지도 학습 (semisupervised learning)&lt;/h4&gt;
&lt;p&gt;레이블이 일부만 있는 데이터. 대부분 지도 학습과 비지도 학습의 조합으로 이루어져 있다.&lt;/p&gt;

&lt;h4 id=&quot;강화-학습-reinforcement-learning&quot;&gt;강화 학습 (reinforcement learning)&lt;/h4&gt;
&lt;p&gt;에이전트(학습 시스템)이 환경을 관찰해서 행동을 실행하고 그 결과로 보상 또는 벌점을 받는다. 시간이 지나면서 가장 큰 보상을 얻기 위해 정책(policy)라고 부르는 최상의 전략을 스스로 학습한다.&lt;/p&gt;

&lt;h3 id=&quot;실시간-훈련-여부&quot;&gt;실시간 훈련 여부&lt;/h3&gt;
&lt;h4 id=&quot;배치-학습-batch-learning&quot;&gt;배치 학습 (batch learning)&lt;/h4&gt;
&lt;p&gt;시스템이 가용한 데이터를 모두 사용해 훈련한다. 즉 먼저 시스템을 훈련시키고 더 이상의 학습 없이 제품 시스템에 적용한다. 오프라인 학습(offline learning)이라고 한다. 이는 컴퓨팅 자원이 많이 필요하다는 점을 고려해야 한다.&lt;/p&gt;

&lt;h4 id=&quot;온라인-학습-online-learning&quot;&gt;온라인 학습 (online learning)&lt;/h4&gt;
&lt;p&gt;데이터를 순차적으로 한 개씩 또는 미니배치(mini-batch) 단위로 훈련한다. 매 학습 단계가 빠르고 비용이 적게 들어 데이터가 도착하는 즉시 학습할 수 있다. 그러나 나쁜 데이터가 주입되었을 때 시스템 성능이 점진적으로 감소하기 때문에 모니터링이 필요하다.&lt;/p&gt;</content><author><name>KYG</name></author><category term="ML" /><summary type="html">핸즈온 머신러닝의 머신러닝 내용 일부를 정리. 머신러닝 시스템의 종류 머신러닝 시스템은 다음과 같이 분류할 수 있지만 서로 배타적이지 않고 원하는 대로 연결 가능하다. 훈련 지도 여부 : 지도 학습, 비지도 학습, 준지도 학습, 강화 학습 실시간 훈련 여부 : 온라인 학습, 배치 학습</summary></entry></feed>