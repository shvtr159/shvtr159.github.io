---
title: 'PU-GAN: A Point Cloud Upsampling Adversarial Network'
use_math: true
categories:
- 논문
---

## Introduction
PU-Net, EC-Net, MPU 등의 network들은 학습을 통해 point cloud upsampling의 장점을 입증했다. 그러나 이 네트워크들은 sparse하고 non-uniform한 low-quality inputs로부터 좋은 결과를 얻지 못할 수 있다. 그래서 upsampling과 data amendment 능력을 결합한 PU-GAN을 제안한다. 주된 기여는 latent space에서 다양한 point 분포를 생성하도록 generator를 학습시키고, 이 point set에 대해 implicit하게 평하가는 데 도움이 되는 discriminator network이다. 그러나 generator와 discriminator간의 균형을 맞추고 낮은 수렴 경향을 피하기 어려운 문제가 있다. Thus, we first improve the point generation quality, or equivalently the feature expansion capability, of the generator, by constructing an up-down-up unit to expand point features by upsampling also their differences for self-correction.  또, feature integration quality를 향상시키기 위해 self-attention unit을 사용한다. 마지막으로, 결과의 distribution uniformity를 향상시키고 discriminator가 target distribution에서 더 많은 latent pattern을 학습하도록 하기 위해 aadversarial, uniform, reconstruction term을 사용해 end-to-end 로 network를 학습시키는 compound loss를 추가로 사용한다.
##  Method
### 3.1 Overview
point 수가 $N$개인 순서 없는 sparse point set $\mathcal{P}=\{  p_{i}  \}_ {i=1}^{N}$가 주어지면, $rN$개의 point를 가지는 dense point set  $\mathcal{Q}= \{  q_{i} \}_ {i=1}^{rN}$을 생성하는 것을 목표로 한다. 이때, $r$은 upsampling rate이다. $\mathcal{Q}$가 반드시 $\mathcal{P}$의 superset(상위집합)은 아니지만, 출력 $\mathcal{Q}$가 다음 2가지 조건을 만족하기를 원한다.
1. $\mathcal{Q}$는 $\mathcal{P}$와 latent target object의 같은 underlying geometry를 설명해야 하고, 때문에 $\mathcal{Q}$의 point들은 target object의 표면에 있어야 한다.
2. sparse하고 non-uniform한 input $\mathcal{P}$에 대해서도 $\mathcal{Q}$의 point들은 target object 표면에 uniformly-distribute하게 분포되어야 한다.

![image](https://user-images.githubusercontent.com/79836443/133037097-4dc912bb-f9d2-4a0f-83a0-40b3776db7f4.png){:.align-center}

위 PU-GAN의 전체적인 네트워크 구조를 보면, generator는 sparse input $\mathcal{P}$로부터 dense output $\mathcal{Q}$를 생성하고, discriminator는 fake로 생성된 것을 찾는것을 목표로 한다.

### 3.2 Network Architecture
#### 3.2.1  Generator
Figure 2에서 보이듯이, generator는 3개의 component를 가지고있다.

**The feature extraction component** $N\times d$ ($d$ : Input point 속성의 차원 수. $i.e.$, 좌표, 색상, normal 등) 의 input $\mathcal{P}$로부터 feature $\mathbf{F}$를 추출하기 위해 가장 간단한 3D coordinates인것만을 고려하여 $d=3$의 case에 focusing하고, \[Patch-based progressive 3D point set upsampling, CVPR2019\]의 feature extraction 방법을 채택하여 서로 다른  layer들에 걸쳐 feature들을 통합하기 위해 dense connection이 도입됐다.

**The feature expansion component** $\mathbf{F}$를 확장하여 확장된 feature $\mathbf{F_{up}}$을 생성한다. 여기서는 generator가 더 다양한 point distribution을 생성할 수 있도록 $\mathbf{F_{up}}$의 feature variation을 강화시키기 위해 *up-down-up expansion unit* (Figure2의 위쪽)을 설계한다.

**The point set generation component** 먼저, multilayer perceptrons (MLPs) 세트를 통해 $\mathbf{F_{up}}$에서 3D coordiante 세트를 regression한다. feature expansion process가 여전히 local하기 때문에 $\mathbf{F_{up}}$의 feature (또는 latent space의 point들)이 input에 가깝다. 때문에 서로 멀리 떨어진 $rN$ points만을 남기기 위해 network에 farthest sampling setp을 포함한다. 이를 위해 $\mathbf{F}$에서 $\mathbf{F_{up}}$으로 확장할 때, $\mathbf{F_{up}}$에 $(r+2)N$ features를 생성한다.이 전략은 global perspective에서 point set 의 distribution uniformity를 강화한다.

#### 3.2.2 Discriminator
Discriminator의 목표는 generator에서 생성된 $rN$ points의 set을 구분하는 것이다. 이를 위해 처음에는 global feature를 추출하기 위해 \[PCN: Point completion network, 3DV2018\]의 basic network 구조를 이용한다. feature learning을 개선하기 위해  feature concatenation 한 뒤 self-attention unit을 추가한다. 이는 basic MLPs와 비교하여 feature integration을 개선하고 subsequent feature extraction 기능을 개선할 수 있다. 다음으로 global feature를 생성하기 위해 MLPs set와  max pooling를 적용하고 FC layer set를 통해 최종 confidence value를 regression한다. 이 값이 1에 가까울수록 높은 신뢰도의 target distribution에서 온 가능성이 있다고 예측한다.

### 3.3 UP-down-up Expansion Unit

기존 PU-Net, EC-Net, MPU 등의 network들은 학습을 통해 point cloud upsampling의 장점을 입증했다. 그러나 이 네트워크들은 sparse하고 non-uniform한 low-quality inputs로부터 좋은 결과를 얻지 못할 수 있다.
그래서 기존의 point cloud를 deep learning을 사용해서 처리하는 방식과 GAN 기반의 3D shape processing 방식을 결합하여 upsampling을 수행하도록 하였다. 기존 GAN을 이용한 processing은 3D volume 방식이었고 point cloud를 사용한 것은 reconstruction에 가까워 upsampling은 최소로 수행하였다.
